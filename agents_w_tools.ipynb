{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing packages and data\n",
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configure matplotlib for inline plotting in Jupyter\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()  # Enable interactive mode\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "#matplotlib.use('inline')  # or 'Qt5Agg' depending on your system\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import base64\n",
    "\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "from glob import glob\n",
    "\n",
    "import langchain  # Main LangChain import\n",
    "from langchain_openai import ChatOpenAI  # To work with OpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "#from langchain_ollama.llms import OllamaLLM\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI # To work with Gemini (optional)\n",
    "from langchain_core.output_parsers import JsonOutputParser  # To help with structured output\n",
    "from langchain_core.prompts import PromptTemplate  # To help create our prompt\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field  # To help with defining what output structure we want\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain.load.dump import dumps\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Configure Logging\n",
    "# ==========================\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger('ReWOO_LangGraph')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Clear any existing handlers attached to the logger\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler(sys.stdout)\n",
    "f_handler = logging.FileHandler('rewoolanggraph.log', mode='w')\n",
    "\n",
    "c_handler.setLevel(logging.INFO)\n",
    "f_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create formatters and add them to handlers\n",
    "c_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "f_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "c_handler.setFormatter(c_format)\n",
    "f_handler.setFormatter(f_format)\n",
    "\n",
    "# Add handlers to the logger\n",
    "logger.addHandler(c_handler)\n",
    "logger.addHandler(f_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Function to load JSON files\n",
    "# ==========================\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Loading Files\n",
    "# ==========================\n",
    "\n",
    "base_path = 'data/challenges/'\n",
    "\n",
    "# Subset of challenges for testing\n",
    "subset_ids_challenges = load_json(base_path + '28_8x10_challenges.json')\n",
    "subset_ids_evaluation = load_json(base_path + '28_15x15_evaluation.json')\n",
    "\n",
    "# Load evaluation dataset\n",
    "evaluation_challenges = load_json(base_path + 'arc-agi_evaluation_challenges.json')\n",
    "evaluation_solutions = load_json(base_path + 'arc-agi_evaluation_solutions.json')\n",
    "\n",
    "# load training dataset\n",
    "training_challenges = load_json(base_path + 'arc-agi_training_challenges.json')\n",
    "training_solutions = load_json(base_path + 'arc-agi_training_solutions.json')\n",
    "\n",
    "# Filter training challenges and solutions to only include the subset IDs\n",
    "training_challenges = {k: v for k, v in training_challenges.items() if k in subset_ids_challenges}\n",
    "training_solutions = {k: v for k, v in training_solutions.items() if k in subset_ids_challenges}\n",
    "\n",
    "# filter evaluation challenges and solutions to only include the subset IDs\n",
    "evaluation_challenges = {k: v for k, v in evaluation_challenges.items() if k in subset_ids_evaluation}\n",
    "evaluation_solutions = {k: v for k, v in evaluation_solutions.items() if k in subset_ids_evaluation}\n",
    "\n",
    "test_challenges = load_json(base_path + 'arc-agi_test_challenges.json')\n",
    "\n",
    "\n",
    "\n",
    "task_sets = {\n",
    "    'training': {\n",
    "        'challenges': training_challenges,\n",
    "        'solutions': training_solutions,\n",
    "    },\n",
    "    'evaluation': {\n",
    "        'challenges': evaluation_challenges,\n",
    "        'solutions': evaluation_solutions,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Function to load tasks from a pre-loaded task set\n",
    "# ==========================\n",
    "\n",
    "def load_tasks_from_file(task_set):\n",
    "    \"\"\"\n",
    "    Loads the tasks from the pre-loaded JSON data and returns the challenges and solutions tasks.\n",
    "    \"\"\"\n",
    "    challenges = task_set['challenges']\n",
    "    solutions = task_set['solutions']\n",
    "\n",
    "    return challenges, solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered training challenges = 28\n",
      "Number of filtered training solutions = 28\n",
      "{\n",
      "  \"test\": [\n",
      "    {\n",
      "      \"input\": [\n",
      "        [\n",
      "          1,\n",
      "          0,\n",
      "          1,\n",
      "          5,\n",
      "          1,\n",
      "          0,\n",
      "          1\n",
      "        ],\n",
      "        [\n",
      "          0,\n",
      "          1,\n",
      "          0,\n",
      "          5,\n",
      "          1,\n",
      "          0,\n",
      "          1\n",
      "        ],\n",
      "        [\n",
      "          1,\n",
      "          0,\n",
      "          1,\n",
      "          5,\n",
      "          0,\n",
      "          1,\n",
      "          0\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"train\": [\n",
      "    {\n",
      "      \"input\": [\n",
      "        [\n",
      "          1,\n",
      "          0,\n",
      "          0,\n",
      "          5,\n",
      "          0,\n",
      "          1,\n",
      "          0\n",
      "        ],\n",
      "        [\n",
      "          0,\n",
      "          1,\n",
      "          0,\n",
      "          5,\n",
      "          1,\n",
      "          1,\n",
      "          1\n",
      "        ],\n",
      "        [\n",
      "          1,\n",
      "          0,\n",
      "          0,\n",
      "          5,\n",
      "          0,\n",
      "          0,\n",
      "          0\n",
      "        ]\n",
      "      ],\n",
      "      \"output\": [\n",
      "        [\n",
      "          0,\n",
      "          0,\n",
      "          0\n",
      "        ],\n",
      "        [\n",
      "          0,\n",
      "          2,\n",
      "          0\n",
      "        ],\n",
      "        [\n",
      "          0,\n",
      "          0,\n",
      "          0\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"input\": [\n",
      "        [\n",
      "          1,\n",
      "          1,\n",
      "          0,\n",
      "          5,\n",
      "          0,\n",
      "          1,\n",
      "          0\n",
      "        ],\n",
      "        [\n",
      "          0,\n",
      "          0,\n",
      "          1,\n",
      "          5,\n",
      "          1,\n",
      "          1,\n",
      "          1\n",
      "        ],\n",
      "        [\n",
      "          1,\n",
      "          1,\n",
      "          0,\n",
      "          5,\n",
      "          0,\n",
      "          1,\n",
      "          0\n",
      "        ]\n",
      "      ],\n",
      "      \"output\": [\n",
      "        [\n",
      "          0,\n",
      "          2,\n",
      "          0\n",
      "        ],\n",
      "        [\n",
      "          0,\n",
      "          0,\n",
      "          2\n",
      "        ],\n",
      "        [\n",
      "          0,\n",
      "          2,\n",
      "          0\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"input\": [\n",
      "        [\n",
      "          0,\n",
      "          0,\n",
      "          1,\n",
      "          5,\n",
      "          0,\n",
      "          0,\n",
      "          0\n",
      "        ],\n",
      "        [\n",
      "          1,\n",
      "          1,\n",
      "          0,\n",
      "          5,\n",
      "          1,\n",
      "          0,\n",
      "          1\n",
      "        ],\n",
      "        [\n",
      "          0,\n",
      "          1,\n",
      "          1,\n",
      "          5,\n",
      "          1,\n",
      "          0,\n",
      "          1\n",
      "        ]\n",
      "      ],\n",
      "      \"output\": [\n",
      "        [\n",
      "          0,\n",
      "          0,\n",
      "          0\n",
      "        ],\n",
      "        [\n",
      "          2,\n",
      "          0,\n",
      "          0\n",
      "        ],\n",
      "        [\n",
      "          0,\n",
      "          0,\n",
      "          2\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Print Dataset Information\n",
    "# ==========================\n",
    "\n",
    "print(f'Number of filtered training challenges = {len(training_challenges)}')\n",
    "print(f'Number of filtered training solutions = {len(training_solutions)}')\n",
    "\n",
    "# Loading tasks from the 'training' task set\n",
    "challenges, solutions = load_tasks_from_file(task_set=task_sets['training'])\n",
    "print(json.dumps(challenges['0520fde7'], indent=2))  # Accessing a specific challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initializing LLM client to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('api.env')\n",
    "\n",
    "# Get the OpenAI API key from environment variables\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key =os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "# MORE EXPENSIVE MODELS\n",
    "llm_openai = ChatOpenAI(model='gpt-4o', openai_api_key=openai_api_key, max_tokens=5000)\n",
    "#llm_anthropic = ChatAnthropic(model='claude-3-5-sonnet-20241022', anthropic_api_key=anthropic_api_key, max_tokens=3000)\n",
    "\n",
    "# CHEAPER MODELS\n",
    "#llm_openai = ChatOpenAI(model='gpt-4o-mini', openai_api_key=openai_api_key, max_tokens=3000)\n",
    "#llm_anthropic = ChatAnthropic(model='claude-3-haiku-20240307', anthropic_api_key=anthropic_api_key, max_tokens=3000)\n",
    "\n",
    "# LOCAL MODELS USING OLLAMA\n",
    "#llm_local = OllamaLLM(model= \"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for visualizing the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Functions to visualize tasks\n",
    "# ==========================\n",
    "\n",
    "cmap = colors.ListedColormap(\n",
    "   ['#000000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n",
    "    '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25', '#FFFFFF'])\n",
    "norm = colors.Normalize(vmin=0, vmax=10)\n",
    "# print(norm)\n",
    "\n",
    "def plot_one(ax, i, task, train_or_test, input_or_output):\n",
    "    # Check if input_or_output is 'solution' or 'predicted_solution'\n",
    "    if input_or_output == 'solution':\n",
    "        input_matrix = task[train_or_test][i]['output']  # Assuming this is the ground truth solution\n",
    "    elif input_or_output == 'predicted_solution':\n",
    "        input_matrix = task.get('prediction', [])[i]  # Access the predicted solution from task\n",
    "    else:\n",
    "        input_matrix = task[train_or_test][i][input_or_output]\n",
    "\n",
    "    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n",
    "    ax.grid(True, which='both', color='lightgrey', linewidth=0.5)\n",
    "    plt.setp(plt.gcf().get_axes(), xticklabels=[], yticklabels=[])\n",
    "    ax.set_xticks([x - 0.5 for x in range(1 + len(input_matrix[0]))])     \n",
    "    ax.set_yticks([x - 0.5 for x in range(1 + len(input_matrix))])\n",
    "    ax.set_title(f\"{train_or_test} {input_or_output}\")\n",
    "    return None\n",
    "\n",
    "   \n",
    "def plot_eval(task, text, test_input, predicted_solution, actual_solution):\n",
    "    \"\"\"\n",
    "    Plots a single row with three columns: input, predicted solution, and actual solution.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert inputs to numpy arrays if they aren't already\n",
    "        test_input = np.array(test_input)\n",
    "        predicted_solution = np.array(predicted_solution)\n",
    "        actual_solution = np.array(actual_solution)\n",
    "        \n",
    "        plt.close('all')  # Close any existing plots\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        fig.suptitle(f'{text}', fontsize=16, fontweight='bold')\n",
    "\n",
    "        # Plot evaluation input\n",
    "        axs[0].imshow(test_input, cmap=cmap, norm=norm)\n",
    "        axs[0].set_title('Evaluation Input')\n",
    "        axs[0].grid(True, color='lightgrey', linewidth=0.5)\n",
    "        axs[0].set_xticks([x - 0.5 for x in range(1 + len(test_input[0]))]) \n",
    "        axs[0].set_yticks([x - 0.5 for x in range(1 + len(test_input))])\n",
    "\n",
    "        # Plot model's predicted solution\n",
    "        axs[1].imshow(predicted_solution, cmap=cmap, norm=norm)\n",
    "        axs[1].set_title('Model Prediction')\n",
    "        axs[1].grid(True, color='lightgrey', linewidth=0.5)\n",
    "        axs[1].set_xticks([x - 0.5 for x in range(1 + len(predicted_solution[0]))]) \n",
    "        axs[1].set_yticks([x - 0.5 for x in range(1 + len(predicted_solution))])\n",
    "\n",
    "        # Plot actual solution\n",
    "        axs[2].imshow(actual_solution, cmap=cmap, norm=norm)\n",
    "        axs[2].set_title('Actual Solution')\n",
    "        axs[2].grid(True, color='lightgrey', linewidth=0.5)\n",
    "        axs[2].set_xticks([x - 0.5 for x in range(1 + len(actual_solution[0]))]) \n",
    "        axs[2].set_yticks([x - 0.5 for x in range(1 + len(actual_solution))])\n",
    "\n",
    "        # Add value annotations to each cell\n",
    "        for ax, data in zip(axs, [test_input, predicted_solution, actual_solution]):\n",
    "            for i in range(len(data)):\n",
    "                for j in range(len(data[0])):\n",
    "                    ax.text(j, i, str(data[i][j]), \n",
    "                           ha='center', va='center',\n",
    "                           color='white' if data[i][j] in [0, 1, 9] else 'black')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()  # Close the plot after showing it\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in plot_eval: {str(e)}\")\n",
    "        plt.close('all')  # Clean up any partial plots\n",
    " \n",
    "def plot_task(task1, text):    \n",
    "    num_train = len(task1['train'])\n",
    "    w=num_train\n",
    "    fig, axs  = plt.subplots(2, w, figsize=(3*w ,3*2))\n",
    "    plt.suptitle(f'{text}:', fontsize=20, fontweight='bold', y=1)\n",
    "\n",
    "    for j in range(num_train):     \n",
    "        plot_one(axs[0, j], j,task1,'train', 'input')\n",
    "        plot_one(axs[1, j], j,task1,'train', 'output')  \n",
    "    \n",
    "    fig.patch.set_linewidth(5)\n",
    "    fig.patch.set_edgecolor('black') \n",
    "    fig.patch.set_facecolor('#dddddd')\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    return plt    \n",
    "    \n",
    "def openai_encode_image_base64(plt):\n",
    "    import io\n",
    "    plt_stringIObytes = io.BytesIO()\n",
    "    plt.savefig(plt_stringIObytes, format='png')\n",
    "    plt_stringIObytes.seek(0)\n",
    "    base64_image = base64.b64encode(plt_stringIObytes.read()).decode('utf-8')\n",
    "    return {\n",
    "      \"type\": \"image_url\",\n",
    "      \"image_url\": {\n",
    "        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "      }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to make MVP product which is just regular openai model trying to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting train and test pairs to a string format ideal for LLMs\n",
    "def json_task_to_string(challenge_tasks: dict, task_id: str, test_input_index: int) -> str:\n",
    "    \"\"\"\n",
    "    challenge_tasks: dict a list of tasks\n",
    "    task_id: str the id of the task we want to convert to a string\n",
    "    \n",
    "    Convert your json task into a string so you can pass it to your LLM.\n",
    "    This is a crucial step where you can use your creativity to edit how tasks are represented.\n",
    "    \"\"\"\n",
    "    json_task = challenge_tasks[task_id]\n",
    "\n",
    "    final_output = \"\"\n",
    "\n",
    "    train_tasks = json_task['train']\n",
    "    test_task = json_task['test']\n",
    "\n",
    "    final_output = \"Training Examples\\n\"\n",
    "\n",
    "    for i, task in enumerate(train_tasks):\n",
    "        final_output += f\"Example {i + 1}: Input\\n[\"\n",
    "        for row in task['input']:\n",
    "            final_output += f\"\\n{str(row)},\"\n",
    "\n",
    "        final_output += \"]\\n\\n\"\n",
    "        final_output += f\"Example {i + 1}: Output\\n[\"\n",
    "\n",
    "        for row in task['output']:\n",
    "            final_output += f\"\\n{str(row)},\"\n",
    "\n",
    "        final_output += \"]\\n\\n\"\n",
    "\n",
    "    final_output += \"Test\\n[\"\n",
    "    for row in test_task[test_input_index]['input']:\n",
    "        final_output += f\"\\n{str(row)}\"\n",
    "\n",
    "    final_output += \"]\\n\\nYour Response:\"\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[1, 0, 0, 5, 0, 1, 0],\n",
      "[0, 1, 0, 5, 1, 1, 1],\n",
      "[1, 0, 0, 5, 0, 0, 0],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[0, 0, 0],\n",
      "[0, 2, 0],\n",
      "[0, 0, 0],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[1, 1, 0, 5, 0, 1, 0],\n",
      "[0, 0, 1, 5, 1, 1, 1],\n",
      "[1, 1, 0, 5, 0, 1, 0],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[0, 2, 0],\n",
      "[0, 0, 2],\n",
      "[0, 2, 0],]\n",
      "\n",
      "Example 3: Input\n",
      "[\n",
      "[0, 0, 1, 5, 0, 0, 0],\n",
      "[1, 1, 0, 5, 1, 0, 1],\n",
      "[0, 1, 1, 5, 1, 0, 1],]\n",
      "\n",
      "Example 3: Output\n",
      "[\n",
      "[0, 0, 0],\n",
      "[2, 0, 0],\n",
      "[0, 0, 2],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[1, 0, 1, 5, 1, 0, 1]\n",
      "[0, 1, 0, 5, 1, 0, 1]\n",
      "[1, 0, 1, 5, 0, 1, 0]]\n",
      "\n",
      "Your Response:\n"
     ]
    }
   ],
   "source": [
    "# an example of how the function works\n",
    "task_string = json_task_to_string(challenges, '0520fde7', 0)\n",
    "print (task_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a json output parser to parse the output, since LLMs aren't perfect at generating valid json\n",
    "# Defining a prediction as a list of lists\n",
    "class ARCPrediction(BaseModel):\n",
    "    prediction: List[List] = Field(..., description=\"A prediction for a task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up langgraph for mUlTiaGenTiC sYstEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the state for the graph\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    patterns: Annotated[list, add_messages]\n",
    "    code: str\n",
    "    prediction: List[List]\n",
    "    task_string: str\n",
    "    task_data: dict\n",
    "    test_input_index: int\n",
    "    predicted_grid_size: str  # Add this line\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating tools for the agents to manipulate the gridz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def get_size(grid):\n",
    "    ''' Returns the size of the grid in 2 axes '''\n",
    "    return (len(grid), len(grid[0]))\n",
    "\n",
    "def get_middle(coords):\n",
    "    ''' Returns the middle (centroid) of the coordinates '''\n",
    "    x_sum, y_sum = 0, 0\n",
    "    for (x, y) in coords:\n",
    "        x_sum += int(x)\n",
    "        y_sum += int(y)\n",
    "    return (int(x_sum / len(coords) + 0.5), int(y_sum / len(coords) + 0.5))\n",
    "\n",
    "def get_anchor(coords):\n",
    "    ''' Returns the top-left and bottom-right anchors of the shape '''\n",
    "    min_x, min_y = float('inf'), float('inf')\n",
    "    max_x, max_y = float('-inf'), float('-inf')\n",
    "    for (x, y) in coords:\n",
    "        min_x = min(x, min_x)\n",
    "        min_y = min(y, min_y)\n",
    "        max_x = max(x, max_x)\n",
    "        max_y = max(y, max_y)\n",
    "    return (min_x, min_y), (max_x, max_y)\n",
    "\n",
    "def array_to_string(grid):\n",
    "    ''' Converts numerical grid to string representation '''\n",
    "    # If grid is already in string form, just return it\n",
    "    if isinstance(grid[0][0], str):\n",
    "        return grid\n",
    "\n",
    "    mapping = {0: '.', 1: 'a', 2: 'b', 3: 'c', 4: 'd',\n",
    "               5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j'}\n",
    "    newgrid = [[mapping.get(cell, '.') for cell in row] for row in grid]\n",
    "    return newgrid\n",
    "\n",
    "def string_to_array(grid):\n",
    "    ''' Converts string grid to numerical representation '''\n",
    "    # If grid is already in integer form, just return it\n",
    "    if isinstance(grid[0][0], int):\n",
    "        return grid\n",
    "\n",
    "    mapping = {'.': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4,\n",
    "               'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10}\n",
    "    newgrid = [[mapping.get(cell, 0) for cell in row] for row in grid]\n",
    "    return newgrid\n",
    "\n",
    "def get_pixel_coords(grid):\n",
    "    ''' Gets the coordinates of all the pixel values '''\n",
    "    pixel_coord = {}\n",
    "    for row in range(len(grid)):\n",
    "        for col in range(len(grid[0])):\n",
    "            value = grid[row][col]\n",
    "            if value != 0:  # We assume '0' represents empty space\n",
    "                if value in pixel_coord:\n",
    "                    pixel_coord[value].append((row, col))\n",
    "                else:\n",
    "                    pixel_coord[value] = [(row, col)]\n",
    "    return dict(sorted(pixel_coord.items(), key=lambda x: -len(x[1])))\n",
    "\n",
    "def obj_to_coords(obj):\n",
    "    ''' Converts an object with a grid and top-left coordinate to a list of absolute coordinates '''\n",
    "    coords = []\n",
    "    x, y = obj['tl']\n",
    "    height, width = len(obj['grid']), len(obj['grid'][0])\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if obj['grid'][i][j] != 0:\n",
    "                coords.append((x + i, y + j))\n",
    "    return coords\n",
    "\n",
    "def create_object(grid, coords):\n",
    "    ''' Create an object based on the existing grid and the coordinates of it '''\n",
    "    (min_x, min_y), (max_x, max_y) = get_anchor(coords)\n",
    "    newgrid = [[0 for _ in range(max_y - min_y + 1)] for _ in range(max_x - min_x + 1)]\n",
    "    for (x, y) in coords:\n",
    "        if grid[x][y] == 0:\n",
    "            newgrid[x - min_x][y - min_y] = -1  # Indicate empty spot with -1\n",
    "        else:\n",
    "            newgrid[x - min_x][y - min_y] = grid[x][y]\n",
    "    return {'tl': (min_x, min_y), 'grid': newgrid}\n",
    "\n",
    "def get_objects(grid, diag=False, multicolor=False, by_row=False, by_col=False, by_color=False, more_info=True):\n",
    "    '''\n",
    "    Identifies and extracts distinct objects from a grid.\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The input grid where each cell contains an integer value representing a color or empty space.\n",
    "    - diag (bool, optional): If True, considers diagonal connections when identifying objects. Defaults to False.\n",
    "    - multicolor (bool, optional): If True, allows objects to consist of multiple colors. Defaults to False.\n",
    "    - by_row (bool, optional): If True, splits objects by rows. Defaults to False.\n",
    "    - by_col (bool, optional): If True, splits objects by columns. Defaults to False.\n",
    "    - by_color (bool, optional): If True, groups each color as a separate object. Defaults to False.\n",
    "    - more_info (bool, optional): If True, includes additional details about each object. Defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "    - list of dict: A list of dictionaries, each representing an object with:\n",
    "        - 'tl' (tuple of int): Top-left coordinate of the object.\n",
    "        - 'grid' (list of list of int): 2D grid representing the object's shape and colors.\n",
    "        - 'size' (tuple of int): Dimensions of the object's grid (rows, columns).\n",
    "        - 'cell_count' (int): Number of cells that make up the object.\n",
    "        - 'shape' (list of list of int): Binary representation of the object's shape (1 for filled, 0 for empty).\n",
    "    '''\n",
    "    rows = len(grid)\n",
    "    cols = len(grid[0])\n",
    "    visited = set()\n",
    "    objects = []\n",
    "    missing_color = False\n",
    "    \n",
    "    # Check whether there is a missing color (using '10' to denote missing color)\n",
    "    for each in grid:\n",
    "        for cell in each:\n",
    "            if cell == 10:\n",
    "                missing_color = True\n",
    "\n",
    "    def is_valid(grid, row, col, value):\n",
    "        # multicolor can return any cell as long as it is not visited and not a blank\n",
    "        if multicolor:\n",
    "            return (0 <= row < rows and 0 <= col < cols and \n",
    "                    (row, col) not in visited and grid[row][col] != 0 and grid[row][col] != -1)\n",
    "        else:\n",
    "            return (0 <= row < rows and 0 <= col < cols and \n",
    "                    (row, col) not in visited and grid[row][col] == value)\n",
    "\n",
    "    def dfs(grid, row, col, value):\n",
    "        if is_valid(grid, row, col, value):\n",
    "            visited.add((row, col))\n",
    "            object_coords.add((row, col))\n",
    "            \n",
    "            if not by_row:\n",
    "                dfs(grid, row - 1, col, value)  # up\n",
    "                dfs(grid, row + 1, col, value)  # down\n",
    "            if not by_col:\n",
    "                dfs(grid, row, col - 1, value)  # left\n",
    "                dfs(grid, row, col + 1, value)  # right\n",
    "            if not by_row and not by_col and diag:\n",
    "                dfs(grid, row - 1, col - 1, value)  # top-left diagonal\n",
    "                dfs(grid, row - 1, col + 1, value)  # top-right diagonal\n",
    "                dfs(grid, row + 1, col - 1, value)  # bottom-left diagonal\n",
    "                dfs(grid, row + 1, col + 1, value)  # bottom-right diagonal\n",
    "\n",
    "    # If by_color, we don't need to do dfs\n",
    "    if by_color:\n",
    "        pixels = get_pixel_coords(grid)\n",
    "        for key, value in pixels.items():\n",
    "            object_coords = value\n",
    "            object_dict = create_object(grid, object_coords)\n",
    "            if more_info:\n",
    "                object_dict['size'] = (len(object_dict['grid']), len(object_dict['grid'][0]))\n",
    "                object_dict['cell_count'] = len(object_coords)\n",
    "                object_dict['shape'] = [[1 if cell != 0 else 0 for cell in row] for row in object_dict['grid']]\n",
    "            objects.append(object_dict)\n",
    "    else:\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                value = grid[row][col]\n",
    "                if (row, col) not in visited:\n",
    "                    if value == 0 or value == -1:\n",
    "                        continue\n",
    "                    object_coords = set()\n",
    "                    dfs(grid, row, col, value)\n",
    "                    if not object_coords:\n",
    "                        continue  # No object found\n",
    "                    object_dict = create_object(grid, object_coords)\n",
    "                    if more_info:\n",
    "                        object_dict['size'] = (len(object_dict['grid']), len(object_dict['grid'][0]))\n",
    "                        object_dict['cell_count'] = len(object_coords)\n",
    "                        object_dict['shape'] = [[1 if cell != 0 else 0 for cell in row] for row in object_dict['grid']]\n",
    "                    objects.append(object_dict)\n",
    "\n",
    "        # If there's no color '10', process inner objects\n",
    "        if not missing_color:\n",
    "            multicolor = False\n",
    "            new_objects = []\n",
    "            for obj in objects:\n",
    "                visited_inner = set()\n",
    "                newgrid = obj['grid']\n",
    "                rows_new = len(newgrid)\n",
    "                cols_new = len(newgrid[0])\n",
    "                for row in range(rows_new):\n",
    "                    for col in range(cols_new):\n",
    "                        if (row, col) not in visited_inner:\n",
    "                            if newgrid[row][col] == 0:\n",
    "                                object_coords = set()\n",
    "                                # Define a separate DFS for inner objects\n",
    "                                def dfs_inner(grid, row, col, value):\n",
    "                                    if (0 <= row < rows_new and 0 <= col < cols_new and\n",
    "                                        (row, col) not in visited_inner and grid[row][col] == value):\n",
    "                                        visited_inner.add((row, col))\n",
    "                                        object_coords.add((row, col))\n",
    "                                        if not by_row:\n",
    "                                            dfs_inner(grid, row - 1, col, value)  # up\n",
    "                                            dfs_inner(grid, row + 1, col, value)  # down\n",
    "                                        if not by_col:\n",
    "                                            dfs_inner(grid, row, col - 1, value)  # left\n",
    "                                            dfs_inner(grid, row, col + 1, value)  # right\n",
    "                                        if not by_row and not by_col and diag:\n",
    "                                            dfs_inner(grid, row - 1, col - 1, value)  # top-left diagonal\n",
    "                                            dfs_inner(grid, row - 1, col + 1, value)  # top-right diagonal\n",
    "                                            dfs_inner(grid, row + 1, col - 1, value)  # bottom-left diagonal\n",
    "                                            dfs_inner(grid, row + 1, col + 1, value)  # bottom-right diagonal\n",
    "\n",
    "                                dfs_inner(newgrid, row, col, 0)\n",
    "                                # Check if the object does not touch the boundary\n",
    "                                boundary = False\n",
    "                                for x, y in object_coords:\n",
    "                                    if x == 0 or x == rows_new - 1 or y == 0 or y == cols_new - 1:\n",
    "                                        boundary = True\n",
    "                                        break\n",
    "                                if boundary:\n",
    "                                    continue  # Skip objects touching the boundary\n",
    "                                if not object_coords:\n",
    "                                    continue  # No inner object found\n",
    "                                object_dict = create_object(newgrid, object_coords)\n",
    "                                cur_x, cur_y = object_dict['tl']\n",
    "                                base_x, base_y = obj['tl']\n",
    "                                object_dict['tl'] = (cur_x + base_x, cur_y + base_y)\n",
    "                                if more_info:\n",
    "                                    object_dict['size'] = (len(object_dict['grid']), len(object_dict['grid'][0]))\n",
    "                                    object_dict['cell_count'] = len(object_coords)\n",
    "                                    object_dict['shape'] = [[1 if cell != 0 else 0 for cell in row] for row in object_dict['grid']]\n",
    "                                new_objects.append(object_dict)\n",
    "            objects.extend(new_objects)\n",
    "    return objects\n",
    "\n",
    "def combine_object(obj1, obj2):\n",
    "    ''' Combines two objects into a single object, overlaying them on a new grid '''\n",
    "    # If not an instance of object, create it\n",
    "    if not isinstance(obj1, dict):\n",
    "        obj1 = {'tl': (0, 0), 'grid': obj1}\n",
    "    if not isinstance(obj2, dict):\n",
    "        obj2 = {'tl': (0, 0), 'grid': obj2}\n",
    "    grid = empty_grid(30, 30)\n",
    "    grid = fill_grid(grid, obj1['tl'], obj1['grid'])\n",
    "    grid = fill_grid(grid, obj2['tl'], obj2['grid'])\n",
    "    obj_coords = obj_to_coords(obj1)\n",
    "    obj_coords2 = obj_to_coords(obj2)\n",
    "    obj_coords.extend(obj_coords2)\n",
    "    return create_object(grid, obj_coords)\n",
    "    \n",
    "def tight_fit(grid):\n",
    "    ''' Removes all empty rows and columns from the grid, returning a tightly fitted version '''\n",
    "    objects = get_objects(grid, more_info=False)\n",
    "    if not objects:\n",
    "        return grid  # Return the original grid if no objects found\n",
    "    obj = objects[0]\n",
    "    for each in objects[1:]:\n",
    "        obj = combine_object(obj, each)\n",
    "    return obj['grid']\n",
    "                           \n",
    "def fill_grid(grid, tl, pattern): \n",
    "    ''' \n",
    "    Fills a section of the grid with a specified pattern starting from a top-left coordinate.\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The original grid to be filled.\n",
    "    - tl (tuple of int): Top-left coordinate (row, col) where the pattern should be placed.\n",
    "    - pattern (list of list of int or int): The pattern to fill into the grid. If an integer, it's treated as a single-cell pattern.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: The grid after the pattern has been filled in.\n",
    "    '''\n",
    "    x, y = tl\n",
    "    if not isinstance(pattern, list):\n",
    "        pattern = [[pattern]]\n",
    "    for row in range(len(pattern)):\n",
    "        for col in range(len(pattern[0])):\n",
    "            if 0 <= row + x < len(grid) and 0 <= col + y < len(grid[0]): \n",
    "                if pattern[row][col] != -1:\n",
    "                    grid[row + x][col + y] = pattern[row][col]\n",
    "    return grid\n",
    "\n",
    "def fill_object(grid, obj, align=False):\n",
    "    ''' \n",
    "    Places an object's grid into a larger grid at the object's top-left coordinate.\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The larger grid where the object will be placed.\n",
    "    - obj (dict): The object to place, with keys 'tl' (top-left coordinate) and 'grid' (object's grid).\n",
    "    - align (bool, optional): If True, returns the object's grid without placing it into the larger grid. Defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: The grid after the object has been placed.\n",
    "    '''\n",
    "    if align:\n",
    "        return obj['grid']\n",
    "    return fill_grid(grid, obj['tl'], obj['grid'])\n",
    "\n",
    "def empty_grid(row, col):\n",
    "    ''' \n",
    "    Creates an empty grid of specified dimensions.\n",
    "    \n",
    "    Parameters:\n",
    "    - row (int): Number of rows in the grid.\n",
    "    - col (int): Number of columns in the grid.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: A grid filled with zeros.\n",
    "    '''\n",
    "    grid = [[0 for _ in range(col)] for _ in range(row)]\n",
    "    return grid\n",
    "\n",
    "def crop_grid(grid, tl, br): \n",
    "    ''' \n",
    "    Extracts a subgrid from the original grid defined by top-left and bottom-right coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The original grid to crop.\n",
    "    - tl (tuple of int): Top-left coordinate (row, col) of the subgrid.\n",
    "    - br (tuple of int): Bottom-right coordinate (row, col) of the subgrid.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: The cropped subgrid.\n",
    "    '''\n",
    "    return [[grid[i][j] for j in range(tl[1], br[1] + 1)] for i in range(tl[0], br[0] + 1)]\n",
    "\n",
    "def fill_between_coords(grid, coord1, coord2, value): \n",
    "    ''' \n",
    "    Fills all cells between two coordinates with a specified value, forming a line.\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The grid to modify.\n",
    "    - coord1 (tuple of int): Starting coordinate (row, col).\n",
    "    - coord2 (tuple of int): Ending coordinate (row, col).\n",
    "    - value (int): The value to fill between the coordinates.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: The grid after filling the specified line.\n",
    "    '''\n",
    "    # Fill a single point\n",
    "    if coord1 == coord2:\n",
    "        grid[coord1[0]][coord1[1]] = value\n",
    "        return grid\n",
    "\n",
    "    # Fill a line\n",
    "    row_diff = coord1[0] - coord2[0]\n",
    "    col_diff = coord1[1] - coord2[1]\n",
    "    maxdist = max(abs(row_diff), abs(col_diff))\n",
    "    height, width = len(grid), len(grid[0])\n",
    "    for i in range(maxdist + 1):\n",
    "        row_pos = coord1[0] - (i * row_diff) // maxdist\n",
    "        col_pos = coord1[1] - (i * col_diff) // maxdist\n",
    "        if 0 <= row_pos < height and 0 <= col_pos < width:\n",
    "            grid[row_pos][col_pos] = value\n",
    "    return grid\n",
    "\n",
    "def rotate_clockwise(grid, degree=90):\n",
    "    ''' \n",
    "    Rotates the grid clockwise by a specified degree.\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The grid to rotate.\n",
    "    - degree (int, optional): The degree of rotation (90, 180, or 270). Defaults to 90.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: The rotated grid.\n",
    "    '''\n",
    "    newgrid = copy.deepcopy(grid)\n",
    "    for _ in range(degree // 90):\n",
    "        # Transpose the grid\n",
    "        transposed_grid = [list(row) for row in zip(*newgrid)]\n",
    "        # Reverse each row to get a clockwise rotation\n",
    "        newgrid = [row[::-1] for row in transposed_grid]\n",
    "    return newgrid\n",
    "\n",
    "def horizontal_flip(grid):\n",
    "    ''' \n",
    "    Flips the grid horizontally (mirror image along the vertical axis).\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The grid to flip.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: The horizontally flipped grid.\n",
    "    '''\n",
    "    return [row[::-1] for row in grid]\n",
    "\n",
    "def vertical_flip(grid):\n",
    "    ''' \n",
    "    Flips the grid vertically (mirror image along the horizontal axis).\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The grid to flip.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: The vertically flipped grid.\n",
    "    '''\n",
    "    return grid[::-1]\n",
    "\n",
    "def fill_value(grid, pos, value):\n",
    "    ''' \n",
    "    Fills a specific position in the grid with the given value.\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The grid to be modified.\n",
    "    - pos (tuple of int): The (x, y) position to fill.\n",
    "    - value (int): The value to place at the specified position.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: The modified grid.\n",
    "    '''\n",
    "    x, y = pos\n",
    "    if x < 0 or x >= len(grid) or y < 0 or y >= len(grid[0]):\n",
    "        return grid\n",
    "    grid[x][y] = value\n",
    "    return grid\n",
    "\n",
    "def replace(grid, pattern1, pattern2):\n",
    "    ''' \n",
    "    Replaces all occurrences of a subgrid (pattern1) with another subgrid (pattern2) in the given grid.\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The grid to be modified.\n",
    "    - pattern1 (list of list of int): The subgrid to be replaced.\n",
    "    - pattern2 (list of list of int): The subgrid to replace with.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: The modified grid.\n",
    "    '''\n",
    "    if not isinstance(pattern1, list):\n",
    "        pattern1 = [[pattern1]]\n",
    "    if not isinstance(pattern2, list):\n",
    "        pattern2 = [[pattern2]]\n",
    "    height, width = len(pattern1), len(pattern1[0])\n",
    "    for i in range(len(grid) - height + 1):\n",
    "        for j in range(len(grid[0]) - width + 1):\n",
    "            if crop_grid(grid, (i, j), (i + height - 1, j + width - 1)) == pattern1:\n",
    "                grid = fill_grid(grid, (i, j), pattern2)\n",
    "    return grid\n",
    "\n",
    "def fill_rect(grid, tl, br, value):\n",
    "    ''' \n",
    "    Fills a rectangular area in the grid with the specified value.\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The grid to be modified.\n",
    "    - tl (tuple of int): The (x, y) coordinates of the top-left corner of the rectangle.\n",
    "    - br (tuple of int): The (x, y) coordinates of the bottom-right corner of the rectangle.\n",
    "    - value (int): The value to fill the rectangle with.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: The modified grid.\n",
    "    '''\n",
    "    for row in range(tl[0], br[0] + 1):\n",
    "        for col in range(tl[1], br[1] + 1):\n",
    "            grid = fill_value(grid, (row, col), value)\n",
    "    return grid\n",
    "\n",
    "def fill_row(grid, row_num, value, start_col=0, end_col=30):\n",
    "    ''' \n",
    "    Fills a specific row in the grid with the given value from start_col to end_col.\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The grid to be modified.\n",
    "    - row_num (int): The index of the row to fill.\n",
    "    - value (int): The value to fill the row with.\n",
    "    - start_col (int, optional): The starting column index (inclusive). Defaults to 0.\n",
    "    - end_col (int, optional): The ending column index (inclusive). Defaults to 30.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: The modified grid.\n",
    "    '''\n",
    "    for col_num in range(start_col, end_col + 1):\n",
    "        grid = fill_value(grid, (row_num, col_num), value)\n",
    "    return grid\n",
    "\n",
    "def fill_col(grid, col_num, value, start_row=0, end_row=30): \n",
    "    ''' \n",
    "    Fills a specific column in the grid with the given value from start_row to end_row.\n",
    "    \n",
    "    Parameters:\n",
    "    - grid (list of list of int): The grid to be modified.\n",
    "    - col_num (int): The index of the column to fill.\n",
    "    - value (int): The value to fill the column with.\n",
    "    - start_row (int, optional): The starting row index (inclusive). Defaults to 0.\n",
    "    - end_row (int, optional): The ending row index (inclusive). Defaults to 30.\n",
    "    \n",
    "    Returns:\n",
    "    - list of list of int: The modified grid.\n",
    "    '''\n",
    "    for row_num in range(start_row, end_row + 1):\n",
    "        grid = fill_value(grid, (row_num, col_num), value)\n",
    "    return grid\n",
    "\n",
    "def change_object_pos(obj, new_tl):\n",
    "    ''' \n",
    "    Changes the top-left position of an object to a new position.\n",
    "    \n",
    "    Parameters:\n",
    "    - obj (dict): The object with 'tl' (top-left) and 'grid' keys.\n",
    "    - new_tl (tuple of int): The new (x, y) coordinates for the top-left position.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: The object with the updated top-left position.\n",
    "    '''\n",
    "    obj['tl'] = new_tl\n",
    "    return obj\n",
    "\n",
    "def change_object_color(obj, value):\n",
    "    ''' \n",
    "    Changes the color of all non-zero cells in the object's grid to the specified value.\n",
    "    \n",
    "    Parameters:\n",
    "    - obj (dict): The object with 'tl' (top-left) and 'grid' keys.\n",
    "    - value (int): The new color value to apply.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: The object with the updated colors.\n",
    "    '''\n",
    "    for row in range(len(obj['grid'])):\n",
    "        for col in range(len(obj['grid'][0])):\n",
    "            if obj['grid'][row][col] != 0:\n",
    "                obj['grid'][row][col] = value\n",
    "    return obj\n",
    "\n",
    "def get_object_color(obj):\n",
    "    ''' \n",
    "    Retrieves the color of the first non-zero cell in the object's grid.\n",
    "    \n",
    "    Parameters:\n",
    "    - obj (dict): The object with 'tl' (top-left) and 'grid' keys.\n",
    "    \n",
    "    Returns:\n",
    "    - int: The color value of the first non-zero cell, or 0 if all cells are zero.\n",
    "    '''\n",
    "    for row in range(len(obj['grid'])):\n",
    "        for col in range(len(obj['grid'][0])):\n",
    "            if obj['grid'][row][col] != 0:\n",
    "                return obj['grid'][row][col]\n",
    "    return 0\n",
    "\n",
    "# Conditional Functions\n",
    "def object_contains_color(obj, value):\n",
    "    ''' \n",
    "    Returns True if the object contains the specified color, False otherwise.\n",
    "    \n",
    "    Parameters:\n",
    "    - obj (dict): The object to check, represented as a dictionary with 'grid' key for the object's grid.\n",
    "    - value (int): The color value to search for within the object's grid.\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if the color is found in the object's grid, False otherwise.\n",
    "    '''\n",
    "    for row in range(len(obj['grid'])):\n",
    "        for col in range(len(obj['grid'][0])):\n",
    "            if obj['grid'][row][col] == value:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def on_same_line(coord1, coord2, line_type):\n",
    "    ''' \n",
    "    Returns True if coord1 is on the same line as coord2 based on the specified line_type.\n",
    "    \n",
    "    Parameters:\n",
    "    - coord1 (tuple of int): The first coordinate as a (row, col) tuple.\n",
    "    - coord2 (tuple of int): The second coordinate as a (row, col) tuple.\n",
    "    - line_type (str): The type of line to check; can be 'row', 'col', or 'diag'.\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if the coordinates are aligned according to the specified line type, False otherwise.\n",
    "    '''\n",
    "    if line_type == 'row':\n",
    "        return coord1[0] == coord2[0]\n",
    "    if line_type == 'col':\n",
    "        return coord1[1] == coord2[1]\n",
    "    if line_type == 'diag':\n",
    "        return (coord1[0] - coord2[0]) == (coord1[1] - coord2[1])\n",
    "    return False\n",
    "\n",
    "\n",
    "# Unit Tests for Numerical Functions\n",
    "assert get_objects([[1,1,1],[1,0,1],[1,1,1]], more_info=False) == [\n",
    "    {'tl': (0, 0), 'grid': [[1, 1, 1], [1, 0, 1], [1, 1, 1]]},\n",
    "    {'tl': (1, 1), 'grid': [[-1]]}\n",
    "]\n",
    "assert get_pixel_coords([[1,1],[4,6]]) == {1: [(0, 0), (0, 1)], 4: [(1, 0)], 6: [(1, 1)]}\n",
    "assert empty_grid(3, 2) == [[0, 0], [0, 0], [0, 0]]\n",
    "assert crop_grid([[1,1,2],[0,1,2]], (0, 0), (1, 1)) == [[1,1], [0,1]]\n",
    "assert tight_fit([[0,0,0],[0,1,0],[0,0,0]]) == [[1]]\n",
    "assert combine_object({'tl': (0, 0), 'grid': [[1,1],[1,0]]}, {'tl': (1, 1), 'grid': [[6]]}) == {'tl': (0, 0), 'grid': [[1,1], [1,6]]}\n",
    "assert rotate_clockwise([[1,2],[4,5]], 90) == [[4,1],[5,2]]\n",
    "assert rotate_clockwise([[1,2],[4,5]], 270) == [[2,5],[1,4]]\n",
    "assert horizontal_flip([[1,2,3],[4,5,6]]) == [[3,2,1], [6,5,4]]\n",
    "assert vertical_flip([[1,2,3],[4,5,6]]) == [[4,5,6], [1,2,3]]\n",
    "assert replace([[1,0],[1,1]], [[1,1]], [[3,3]]) == [[1,0], [3,3]]\n",
    "assert change_object_color({'tl': (0,0), 'grid': [[1,0]]}, 2) == {'tl': (0,0), 'grid': [[2,0]]}\n",
    "assert get_object_color({'tl': (0,0), 'grid': [[1,0]]}) == 1\n",
    "assert fill_object([[0,0],[0,0]], {'tl': (0,1), 'grid': [[3],[3]]}) == [[0,3],[0,3]]\n",
    "assert fill_value([[0,1],[0,1]], (1,1), 2) == [[0,1],[0,2]]\n",
    "assert fill_row([[1,1],[3,1]], 0, 2) == [[2,2],[3,1]]\n",
    "assert fill_col([[1,1],[3,1]], 0, 2) == [[2,1],[2,1]]\n",
    "assert fill_rect([[1,1],[3,1]], (0,0), (1,1), 2) == [[2,2],[2,2]]\n",
    "assert fill_between_coords([[0,0]], (0,0), (0,1), 1) == [[1,1]]\n",
    "\n",
    "# Conditional Functions\n",
    "\n",
    "def object_contains_color(obj, value):\n",
    "    ''' \n",
    "    Returns True if the object contains the specified color, False otherwise.\n",
    "    \n",
    "    Parameters:\n",
    "    - obj (dict): The object to check, represented as a dictionary with 'grid' key for the object's grid.\n",
    "    - value (int): The color value to search for within the object's grid.\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if the color is found in the object's grid, False otherwise.\n",
    "    '''\n",
    "    for row in range(len(obj['grid'])):\n",
    "        for col in range(len(obj['grid'][0])):\n",
    "            if obj['grid'][row][col] == value:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def on_same_line(coord1, coord2, line_type):\n",
    "    ''' \n",
    "    Returns True if coord1 is on the same line as coord2 based on the specified line_type.\n",
    "    \n",
    "    Parameters:\n",
    "    - coord1 (tuple of int): The first coordinate as a (row, col) tuple.\n",
    "    - coord2 (tuple of int): The second coordinate as a (row, col) tuple.\n",
    "    - line_type (str): The type of line to check; can be 'row', 'col', or 'diag'.\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if the coordinates are aligned according to the specified line type, False otherwise.\n",
    "    '''\n",
    "    if line_type == 'row':\n",
    "        return coord1[0] == coord2[0]\n",
    "    if line_type == 'col':\n",
    "        return coord1[1] == coord2[1]\n",
    "    if line_type == 'diag':\n",
    "        return (coord1[0] - coord2[0]) == (coord1[1] - coord2[1])\n",
    "    return False\n",
    "\n",
    "# Unit Tests for Conditional Functions\n",
    "assert object_contains_color({'tl': (0,0), 'grid': [[1]]}, 1) == True\n",
    "assert on_same_line((1,1), (1,2), 'row') == True\n",
    "assert on_same_line((1,1), (2,1), 'col') == True\n",
    "assert on_same_line((1,1), (2,2), 'diag') == True\n",
    "\n",
    "# Updated Helper Functions with Numerical Representations\n",
    "helper_functions = '''- get_objects(grid, diag=False, multicolor=False, by_row=False, by_col=False, by_color=False, more_info=True): \n",
    "    Takes in grid, returns list of object dictionaries with:\n",
    "        - 'tl': Top-left coordinate of object\n",
    "        - 'grid': 2D grid representing the object\n",
    "    Parameters:\n",
    "        - by_row: Splits objects by grid rows\n",
    "        - by_col: Splits objects by grid columns\n",
    "        - by_color: Groups each color as one object\n",
    "        - multicolor: Allows objects to consist of multiple colors\n",
    "    Notes:\n",
    "        - Empty cells within objects are represented as -1\n",
    "        - If more_info is True, also returns:\n",
    "            - 'size': Dimensions of the grid (rows, columns)\n",
    "            - 'cell_count': Number of cells in the object\n",
    "            - 'shape': Binary representation of the object's shape (1 for filled, 0 for empty)\n",
    "- get_pixel_coords(grid): \n",
    "    Returns a dictionary with keys as pixel values and values as lists of coordinates, sorted from most number of pixels to least\n",
    "- empty_grid(row, col): \n",
    "    Returns an empty grid of height row and width col filled with zeros\n",
    "- crop_grid(grid, tl, br): \n",
    "    Returns a cropped section from top-left (tl) to bottom-right (br) of the grid\n",
    "- tight_fit(grid): \n",
    "    Returns grid with all empty rows and columns removed\n",
    "- combine_object(obj_1, obj_2): \n",
    "    Returns combined object from obj_1 and obj_2. If overlapping, obj_2 overwrites obj_1\n",
    "- rotate_clockwise(grid, degree=90): \n",
    "    Returns grid rotated clockwise by 90, 180, or 270 degrees\n",
    "- horizontal_flip(grid): \n",
    "    Returns a horizontally flipped grid\n",
    "- vertical_flip(grid): \n",
    "    Returns a vertically flipped grid\n",
    "- replace(grid, pattern1, pattern2): \n",
    "    Replaces all occurrences of pattern1 with pattern2 in grid\n",
    "- get_object_color(obj): \n",
    "    Returns the color of the object. If multicolor, returns the first color only\n",
    "- change_object_color(obj, value): \n",
    "    Changes the object's color to the specified value\n",
    "- fill_object(grid, obj, align=False): \n",
    "    Fills grid with object. If align is True, makes grid the same size as the object\n",
    "- fill_row(grid, row_num, value, start_col=0, end_col=30): \n",
    "    Fills a row in the grid with a specified value from start_col to end_col (inclusive)\n",
    "- fill_col(grid, col_num, value, start_row=0, end_row=30): \n",
    "    Fills a column in the grid with a specified value from start_row to end_row (inclusive)\n",
    "- fill_between_coords(grid, coord_1, coord_2, value): \n",
    "    Fills a line between coord_1 and coord_2 with the specified value\n",
    "- fill_rect(grid, tl, br, value): \n",
    "    Fills a rectangle in the grid from top-left (tl) to bottom-right (br) with the specified value\n",
    "- fill_value(grid, pos, value): \n",
    "    Fills a specific position in the grid with the given value\n",
    "- object_contains_color(obj, value): \n",
    "    Returns True/False if object contains a certain value\n",
    "- on_same_line(coord_1, coord_2, line_type): \n",
    "    Returns True/False if coord_1 is on the same line as coord_2. line_type can be one of ['row', 'col', 'diag']\n",
    "'''\n",
    "\n",
    "# Updated Conditional Functions with Numerical Representations\n",
    "conditional_functions = '''\n",
    "object_contains_color(obj, value): returns True/False if object contains a certain value\n",
    "on_same_line(coord_1, coord_2, line_type): Returns True/False if coord_1 is on the same line as coord_2. line_type can be one of ['row', 'col', 'diag']\n",
    "'''\n",
    "\n",
    "all_tools = {\n",
    "    \"get_size\": get_size,\n",
    "    \"get_middle\": get_middle,\n",
    "    \"get_anchor\": get_anchor,\n",
    "    \"array_to_string\": array_to_string,\n",
    "    \"string_to_array\": string_to_array,\n",
    "    \"get_pixel_coords\": get_pixel_coords,\n",
    "    \"obj_to_coords\": obj_to_coords,\n",
    "    \"create_object\": create_object,\n",
    "    \"get_objects\": get_objects,\n",
    "    \"combine_object\": combine_object,\n",
    "    \"tight_fit\": tight_fit,\n",
    "    \"fill_grid\": fill_grid,\n",
    "    \"fill_object\": fill_object,\n",
    "    \"empty_grid\": empty_grid,\n",
    "    \"crop_grid\": crop_grid,\n",
    "    \"fill_between_coords\": fill_between_coords,\n",
    "    \"rotate_clockwise\": rotate_clockwise,\n",
    "    \"horizontal_flip\": horizontal_flip,\n",
    "    \"vertical_flip\": vertical_flip,\n",
    "    \"fill_value\": fill_value,\n",
    "    \"replace\": replace,\n",
    "    \"fill_rect\": fill_rect,\n",
    "    \"fill_row\": fill_row,\n",
    "    \"fill_col\": fill_col,\n",
    "    \"change_object_pos\": change_object_pos,\n",
    "    \"change_object_color\": change_object_color,\n",
    "    \"get_object_color\": get_object_color,\n",
    "    \"object_contains_color\": object_contains_color,\n",
    "    \"on_same_line\": on_same_line,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building nodes for the graph\n",
    "# first initialize the StateGraph\n",
    "graph_builder = StateGraph(State)\n",
    "import ast\n",
    "\n",
    "# ==========================\n",
    "# Function to get the grid size prediction. Has 86% accuracy on the training set.\n",
    "# ==========================\n",
    "def predict_task_grid_size(train_inputs, train_outputs, test_inputs):\n",
    "    \"\"\"\n",
    "    Predicts the grid size of test inputs based on patterns from the train inputs and outputs.\n",
    "\n",
    "    Args:\n",
    "    - train_inputs: List of 2D arrays representing the input grids for training.\n",
    "    - train_outputs: List of 2D arrays representing the output grids for training.\n",
    "    - test_inputs: List of 2D arrays representing the input grids for testing.\n",
    "\n",
    "    Returns:\n",
    "    - pred_test_sizes: List of predicted sizes for the test outputs in 'WxH' format (e.g., '6x6').\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the sizes of train inputs and outputs\n",
    "    train_in_size = [[len(i[0]), len(i)] for i in train_inputs]\n",
    "    train_out_size = [[len(i[0]), len(i)] for i in train_outputs]\n",
    "\n",
    "    # Calculate the sizes of test inputs\n",
    "    test_in_size = [[len(i[0]), len(i)] for i in test_inputs]\n",
    "\n",
    "    # Try to detect consistent ratio patterns\n",
    "    ratio_x = train_in_size[0][0] / train_out_size[0][0]\n",
    "    ratio_y = train_in_size[0][1] / train_out_size[0][1]\n",
    "\n",
    "    # Check for consistent ratios in the training set\n",
    "    for in_size, out_size in zip(train_in_size[1:], train_out_size[1:]):\n",
    "        if in_size[0] / out_size[0] != ratio_x or in_size[1] / out_size[1] != ratio_y:\n",
    "            break\n",
    "    else:\n",
    "        # If the ratio holds, predict based on the ratio\n",
    "        pred_test_sizes = [f\"{int(i[0] / ratio_x)}x{int(i[1] / ratio_y)}\" for i in test_in_size]\n",
    "        return pred_test_sizes\n",
    "\n",
    "    # If ratio-based prediction fails, check for consistent subtraction patterns\n",
    "    sub_x = train_in_size[0][0] - train_out_size[0][0]\n",
    "    sub_y = train_in_size[0][1] - train_out_size[0][1]\n",
    "\n",
    "    for in_size, out_size in zip(train_in_size[1:], train_out_size[1:]):\n",
    "        if in_size[0] - out_size[0] != sub_x or in_size[1] - out_size[1] != sub_y:\n",
    "            break\n",
    "    else:\n",
    "        # If subtraction holds, predict based on subtraction\n",
    "        pred_test_sizes = [f\"{i[0] - sub_x}x{i[1] - sub_y}\" for i in test_in_size if i[0] - sub_x > 0 and i[1] - sub_y > 0]\n",
    "        return pred_test_sizes\n",
    "\n",
    "    # If subtraction-based prediction fails, predict based on the size of the last output grid\n",
    "    last_x = train_out_size[0][0]\n",
    "    last_y = train_out_size[0][1]\n",
    "\n",
    "    for in_size, out_size in zip(train_in_size[1:], train_out_size[1:]):\n",
    "        if out_size[0] != last_x or out_size[1] != last_y:\n",
    "            break\n",
    "    else:\n",
    "        # If all output grids are the same size, predict this size for all test inputs\n",
    "        pred_test_sizes = [f\"{last_x}x{last_y}\" for _ in test_in_size]\n",
    "        return pred_test_sizes\n",
    "\n",
    "    # If no pattern holds, return 'Unknown' indicating an unknown prediction\n",
    "    pred_test_sizes = ['Unknown' for _ in test_in_size]\n",
    "    return pred_test_sizes\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Helper Function to Convert Messages\n",
    "# ==========================\n",
    "\n",
    "def convert_messages(message_list):\n",
    "    return [\n",
    "        msg.content if isinstance(msg, (AIMessage, HumanMessage)) else str(msg)\n",
    "        for msg in message_list\n",
    "    ]\n",
    "\n",
    "def make_serializable(obj):\n",
    "    if isinstance(obj, (AIMessage, HumanMessage)):\n",
    "        return obj.content\n",
    "    elif isinstance(obj, list):\n",
    "        return [make_serializable(item) for item in obj]\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: make_serializable(value) for key, value in obj.items()}\n",
    "    else:\n",
    "        return obj  # Assume the object is already serializable\n",
    "\n",
    "# ==========================\n",
    "# execute_code with Syntax Checking and Logging\n",
    "# ==========================\n",
    "\n",
    "def execute_code(state: State):\n",
    "    code = state['code']\n",
    "    task_data = state['task_data']\n",
    "    test_input_index = state['test_input_index']\n",
    "    test_input = task_data['test'][test_input_index]['input']\n",
    "\n",
    "    # Log the code for debugging\n",
    "    logger.debug(f\"Generated code for solve_task:\\n{code}\")\n",
    "\n",
    "    # Syntax check\n",
    "    try:\n",
    "        ast.parse(code)\n",
    "    except SyntaxError as se:\n",
    "        logger.error(f\"Syntax error in generated code: {se.text}\\nError at line {se.lineno}, column {se.offset}\")\n",
    "        return {\"prediction\": [], \"revised_code\": code}\n",
    "\n",
    "    # Prepare execution environment\n",
    "    local_vars = {}\n",
    "    global_vars = {name: func for name, func in all_tools.items()}\n",
    "\n",
    "    # Include necessary built-in modules\n",
    "    global_vars.update({\n",
    "        \"np\": np,\n",
    "        \"pd\": pd,\n",
    "        \"json\": json,\n",
    "        \"copy\": copy\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        exec(code, global_vars, local_vars)\n",
    "        solve_task = local_vars.get('solve_task') or global_vars.get('solve_task')\n",
    "        if not solve_task:\n",
    "            raise Exception(\"solve_task function not defined in code.\")\n",
    "\n",
    "        # Validate that solve_task is callable and has the correct signature\n",
    "        if not callable(solve_task):\n",
    "            raise Exception(\"solve_task is not callable.\")\n",
    "\n",
    "        expected_signature = inspect.signature(solve_task)\n",
    "        if len(expected_signature.parameters) != 1:\n",
    "            raise Exception(\"solve_task should accept exactly one argument: input_grid.\")\n",
    "\n",
    "        # Execute solve_task and log prediction output\n",
    "        prediction = solve_task(test_input)\n",
    "        if not prediction:\n",
    "            logger.warning(\"solve_task returned an empty output.\")\n",
    "        else:\n",
    "            logger.debug(f\"solve_task output:\\n{prediction}\")\n",
    "    except Exception as e:\n",
    "        prediction = []\n",
    "        logger.error(f\"Error executing solve_task: {e}\")\n",
    "\n",
    "    return {\"prediction\": prediction, \"revised_code\": code}\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# generate_code with Enhanced Prompt\n",
    "# ==========================\n",
    "\n",
    "import re  # Import this at the top of your file to use regex for stripping\n",
    "\n",
    "def clean_code_output(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Function to clean up the code generated by the LLM.\n",
    "    Strips out markdown-like syntax like ```python and ```.\n",
    "    \"\"\"\n",
    "    # Use regex to remove markdown code block markers and unnecessary spaces\n",
    "    cleaned_code = re.sub(r'```[\\w]*', '', code).strip()\n",
    "    return cleaned_code\n",
    "\n",
    "import inspect\n",
    "\n",
    "import inspect\n",
    "\n",
    "def generate_code(state: State):\n",
    "    patterns = state['patterns'][-1]\n",
    "    task_string = state['task_string']\n",
    "\n",
    "    # Log the inputs for debugging\n",
    "    logger.debug(f\"Task String:\\n{task_string}\")\n",
    "    logger.debug(f\"Patterns:\\n{patterns}\")\n",
    "\n",
    "    # Base prompt\n",
    "    base_prompt = (\n",
    "        \"You are an expert Python programmer tasked with creating a function `solve_task(input_grid)`\\n\"\n",
    "        \"to solve a grid manipulation task using the following tools:\\n\"\n",
    "        \"These are the helper functions you can use:\\n{helper_functions}\\n\\n\"\n",
    "        \"Each helper function can be conditional. The conditions can be:\\n\"\n",
    "        \"- by attribute, such as shape, color, position, size, cell number of object\\n\"\n",
    "        \"- the condition can be an attribute on all objects, for instance, objects with the most common or least common value, or objects with the most or least common shape\\n\"\n",
    "        \"- by position of pixels, such as row or column\\n\\n\"\n",
    "        \"These are the conditional functions to help you:\\n{conditional_functions}\\n\\n\"\n",
    "        \"Task Description:\\n{task_string}\\n\\n\"\n",
    "        \"Patterns Detected:\\n{patterns}\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"- Implement the function `solve_task(input_grid)` using **only** the provided tools by their exact names.\\n\"\n",
    "        \"- **Do not define any new helper functions** within or outside `solve_task`.\\n\"\n",
    "        \"- **Do not modify or redefine** any existing tools.\\n\"\n",
    "        \"- Ensure that each tool is called with the correct number of arguments as per its signature.\\n\"\n",
    "        \"- All grid manipulations should be done using lists of lists (integers), not strings.\\n\"\n",
    "        \"- **Do not import any new modules**; use only the tools provided.\\n\"\n",
    "        \"- **Do not include any print statements** or logging within `solve_task`.\\n\"\n",
    "        \"- Return only the Python code for `solve_task` without additional explanations or comments.\\n\\n\"\n",
    "        \"For example, to fill a 3x3 subgrid starting at row 0, column 0 with value 5, you would call:\\n\"\n",
    "        \"fill_grid(grid, 0, 0, 5, 3, 3)\\n\\n\"\n",
    "        \"Your code:\"\n",
    "    )\n",
    "\n",
    "    # Incorporate feedback if available\n",
    "    if 'feedback' in state:\n",
    "        prompt_text = (\n",
    "            f\"{base_prompt}\\n\\n\"\n",
    "            f\"Feedback from previous trial:\\n{state['feedback']}\\n\\n\"\n",
    "            \"Please provide the corrected code:\"\n",
    "        )\n",
    "    else:\n",
    "        prompt_text = base_prompt\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_text,\n",
    "        input_variables=[\"task_string\", \"patterns\", \"helper_functions\", \"conditional_functions\"]\n",
    "    )\n",
    "\n",
    "    # Combine the prompt with the LLM\n",
    "    chain = prompt | llm_openai\n",
    "    code = chain.invoke({\n",
    "        \"task_string\": task_string,\n",
    "        \"patterns\": patterns,\n",
    "        \"helper_functions\": helper_functions,\n",
    "        \"conditional_functions\": conditional_functions\n",
    "    }).content.strip()\n",
    "\n",
    "    # Clean the generated code\n",
    "    code = clean_code_output(code)\n",
    "\n",
    "    # Log the generated code for debugging\n",
    "    logger.debug(f\"Generated Code:\\n{code}\")\n",
    "\n",
    "    return {\"code\": code}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def revise_code(state: State):\n",
    "    code = state['code']\n",
    "\n",
    "    # Define a prompt that explicitly instructs the model to return only the code\n",
    "    # Define the prompt that includes helper and conditional functions\n",
    "    prompt = PromptTemplate(\n",
    "        template=(\n",
    "            \"You are an expert Python programmer. Improve the following `solve_task(input_grid)` function by correcting any syntax errors and handling edge cases.\\n\"\n",
    "            \"Use **only** the provided helper functions and conditional functions listed below.\\n\"\n",
    "            \"Do **not** define any new helper functions or modify existing ones.\\n\"\n",
    "            \"**Return ONLY the corrected `solve_task(input_grid)` function code without any additional text, comments, or explanations.**\\n\\n\"\n",
    "            \"Helper Functions:\\n{helper_functions}\\n\\n\"\n",
    "            \"Conditional Functions:\\n{conditional_functions}\\n\\n\"\n",
    "            \"Code:\\n{code}\\n\\n\"\n",
    "            \"Corrected code:\"\n",
    "        ),\n",
    "        input_variables=[\"code\", \"helper_functions\", \"conditional_functions\"]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm_openai\n",
    "    revised_code = chain.invoke({\n",
    "    \"code\": code,\n",
    "    \"helper_functions\": helper_functions,\n",
    "    \"conditional_functions\": conditional_functions\n",
    "    }).content.strip()\n",
    "\n",
    "    # Use regex to remove any leading statements like \"Here is the corrected code:\", etc.\n",
    "    revised_code = re.sub(r\"^(Here|Here’s|Here is|Corrected code:|Revised code:|The corrected code:|Here's the corrected code|)\", \"\", revised_code, flags=re.IGNORECASE).strip()\n",
    "\n",
    "    # Further clean up by removing any non-code elements, ensuring only the Python code remains\n",
    "    # Strip Markdown code block markers or extraneous non-code content\n",
    "    revised_code = re.sub(r\"^```(?:python)?|```$\", \"\", revised_code, flags=re.MULTILINE).strip()\n",
    "\n",
    "    return {\"code\": revised_code}\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# identify_logic Function\n",
    "# ==========================\n",
    "\n",
    "def identify_logic(state: State):\n",
    "    task_string = state['task_string']\n",
    "    predicted_grid_size = state.get('predicted_grid_size')\n",
    "    \n",
    "    logger.info(f\"Identifying logic for task: {task_string} with predicted grid size: {predicted_grid_size}\")\n",
    "    prompt = PromptTemplate(\n",
    "        template=(\n",
    "            \"You are an AI assistant specializing in puzzle solving.\\n\\n\"\n",
    "            \"You are given a series of inputs and output pairs. \\n\"\n",
    "            \"The values from '1' to '10' represent different colors. '0' is a blank cell. \\n\"\n",
    "            \"For example, [['0','1','0'],['0','0','2']] represents a 2 row x 3 col grid with color 1 at position (1,0) and color 2 at position (2,1).\\n\"\n",
    "            \"Coordinates are 2D positions (row, col), row representing row number, col representing col number, with zero-indexing.\\n\"\n",
    "            \"Input/output pairs may not reflect all possibilities, you are to infer the simplest possible relation.\\n\"\n",
    "            \"Given the following task, identify the logic or pattern present in the training examples.\\n\"\n",
    "            \"Objects are tight-fitted grids (no empty row or column) with a top left coordinate, which can be used for easy manipulation of multiple coordinates.\"\n",
    "            \"Provide a brief description of the logic in bullet points including the predicted grid size.\\n\\n\"\n",
    "            \"Task:\\n{task_string}\\n\\n\"\n",
    "            \"Calculated predicted grid size for this task is {predicted_grid_size}.\\n\\n\"\n",
    "            \"Make your response in the following format:\\n\"\n",
    "            \"reflection: reflect on the answer and provide a brief explanation\\n\"\n",
    "            \"pixel_changes: describe the changes between the input and output pixels, focusing on movement or pattern changes\\n\"\n",
    "            \"object_changes: describe the changes between the input and output objects, focusing on movement, object number, size, shape, position, value, cell count\"\n",
    "        ),\n",
    "        input_variables=[\"task_string\", \"predicted_grid_size\"]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm_openai\n",
    "    output = chain.invoke({\n",
    "        \"task_string\": task_string,\n",
    "        \"predicted_grid_size\": predicted_grid_size\n",
    "    }).content\n",
    "\n",
    "    # Return both the AIMessage and the predicted_grid_size\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=output)],\n",
    "        \"predicted_grid_size\": predicted_grid_size  # Include this in the return\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# recognize_patterns Function\n",
    "# ==========================\n",
    "\n",
    "def recognize_patterns(state: State):\n",
    "    task_analysis = state['task_string']\n",
    "    previous_analysis = state['messages'][-1].content if state['messages'] else \"\"\n",
    "\n",
    "    # Define the prompt for selecting relevant tools\n",
    "    prompt = PromptTemplate(\n",
    "        template=(\n",
    "            \"Based on the task analysis, identify and select the most relevant tools.\\n\\n\"\n",
    "            \"Task Analysis:\\n{task_analysis}\\n\\n\"\n",
    "            \"Available Tools:\\n\"\n",
    "            \"{helper_functions}\\n\\n\"\n",
    "            \"List the tool names that would be useful for this task.\"\n",
    "        ),\n",
    "        input_variables=[\"task_analysis\", \"helper_functions\"]\n",
    "    )\n",
    "\n",
    "    # Run the prompt with the task analysis and all available tools\n",
    "    chain = prompt | llm_anthropic\n",
    "    output = chain.invoke({\n",
    "        \"task_analysis\": task_analysis,\n",
    "        \"helper_functions\": helper_functions\n",
    "    }).content\n",
    "\n",
    "    return {\"patterns\": output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the graph with eches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Adding nodes to the graph for each agent function\n",
    "graph_builder.add_node(\"identify_logic\", identify_logic)\n",
    "graph_builder.add_node(\"recognize_patterns\", recognize_patterns)\n",
    "graph_builder.add_node(\"generate_code\", generate_code)\n",
    "graph_builder.add_node(\"revise_code\", revise_code)\n",
    "graph_builder.add_node(\"execute_code\", execute_code)\n",
    "\n",
    "# Define edges between nodes to establish the flow between agents\n",
    "graph_builder.add_edge(START, \"identify_logic\")\n",
    "graph_builder.add_edge(\"identify_logic\", \"recognize_patterns\")\n",
    "graph_builder.add_edge(\"recognize_patterns\", \"generate_code\")\n",
    "graph_builder.add_edge(\"generate_code\", \"revise_code\")\n",
    "graph_builder.add_edge(\"revise_code\", \"execute_code\")\n",
    "graph_builder.add_edge(\"execute_code\", END)\n",
    "\n",
    "# Compile the graph for execution\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Display the compiled graph visually\n",
    "try:\n",
    "    # Display the graph in Mermaid format with xray view enabled\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(\"Error displaying the graph:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating function to get task prediction, make prompt, make API calls to model and parse output with retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_prediction(challenge_tasks, solutions, task_id, test_input_index, plot=False):\n",
    "    task_string = json_task_to_string(challenge_tasks, task_id, test_input_index)\n",
    "    task_data = challenge_tasks[task_id]\n",
    "    \n",
    "    train_tasks = task_data['train']\n",
    "    train_inputs = [t['input'] for t in train_tasks]\n",
    "    train_outputs = [t['output'] for t in train_tasks]\n",
    "    test_input = task_data['test'][test_input_index]['input']\n",
    "    \n",
    "    # Ensure you have the actual solution\n",
    "    actual_solution = solutions.get(task_id, [])[test_input_index]\n",
    "    \n",
    "    # Predict the grid size\n",
    "    predicted_grid_size = predict_task_grid_size(train_inputs, train_outputs, [test_input])[0]\n",
    "\n",
    "    initial_state = {\n",
    "        'task_string': task_string,\n",
    "        'task_data': task_data,\n",
    "        'test_input_index': test_input_index,\n",
    "        'predicted_grid_size': predicted_grid_size,\n",
    "        'messages': [],\n",
    "        'patterns': [],\n",
    "        'code': '',\n",
    "        'revised_code': '',\n",
    "        'prediction': []\n",
    "    }\n",
    "\n",
    "    # Invoke the graph or prediction model\n",
    "    final_state = graph.invoke(initial_state)\n",
    "    predicted_solution = final_state.get('prediction', [])\n",
    "\n",
    "    # Add debugging print statements\n",
    "    if plot:\n",
    "        try:\n",
    "            print(\"Debug - Plotting dimensions:\")\n",
    "            print(f\"Test input shape: {np.array(test_input).shape}\")\n",
    "            print(f\"Predicted solution shape: {np.array(predicted_solution).shape}\")\n",
    "            print(f\"Actual solution shape: {np.array(actual_solution).shape}\")\n",
    "            \n",
    "            # Only plot if we have valid arrays\n",
    "            if len(predicted_solution) > 0:\n",
    "                logger.info(f\"Plotting results for task {task_id}, attempt {test_input_index}\")\n",
    "                plot_eval(task_data, f\"Task {task_id} Attempt\", test_input, predicted_solution, actual_solution)\n",
    "            else:\n",
    "                logger.warning(\"Skipping plot - predicted solution is empty\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during plotting: {str(e)}\")\n",
    "            plt.close('all')  # Clean up any partial plots\n",
    "\n",
    "    # Extract messages and return structured output\n",
    "    messages = final_state.get('messages', [])\n",
    "    if messages:\n",
    "        messages = [msg.content if isinstance(msg, AIMessage) else msg for msg in messages]\n",
    "\n",
    "    output_details = {\n",
    "        'messages': messages,\n",
    "        'patterns': final_state.get('patterns', []),\n",
    "        'code': final_state.get('code', ''),\n",
    "        'revised_code': final_state.get('revised_code', ''),\n",
    "        'prediction': predicted_solution\n",
    "    }\n",
    "\n",
    "    return output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_serializable(obj):\n",
    "    if isinstance(obj, (AIMessage, HumanMessage)):\n",
    "        return obj.content\n",
    "    elif isinstance(obj, list):\n",
    "        return [make_serializable(item) for item in obj]\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: make_serializable(value) for key, value in obj.items()}\n",
    "    else:\n",
    "        return obj  # Assume the object is already serializable\n",
    "\n",
    "def run_model(challenges, solutions, NUM_ATTEMPTS=2, RETRY_ATTEMPTS=3, NUM_TASKS=None):\n",
    "    submission = {}\n",
    "    detailed_outputs = {}\n",
    "\n",
    "    for i, task_id in enumerate(challenges):\n",
    "        task_attempts = []\n",
    "        detailed_outputs[task_id] = []\n",
    "\n",
    "        # Iterate through each test pair for a prediction\n",
    "        for t, pair in enumerate(challenges[task_id]['test']):\n",
    "            logger.info(f\"Starting task #{i + 1} ({task_id}), pair #{t+1}\")\n",
    "\n",
    "            # Get the predicted grid size\n",
    "            train_tasks = challenges[task_id]['train']\n",
    "            train_inputs = [t['input'] for t in train_tasks]\n",
    "            train_outputs = [t['output'] for t in train_tasks]\n",
    "            test_input = challenges[task_id]['test'][t]['input']\n",
    "            predicted_grid_size = predict_task_grid_size(train_inputs, train_outputs, [test_input])[0]\n",
    "\n",
    "            pair_attempts = {}\n",
    "            pair_detailed = {\n",
    "                'predicted_grid_size': predicted_grid_size  # Add the predicted grid size here\n",
    "            }\n",
    "\n",
    "            # Make attempts with retries\n",
    "            for attempt in range(1, NUM_ATTEMPTS + 1):\n",
    "                attempt_key = f\"attempt_{attempt}\"\n",
    "                pair_attempts[attempt_key] = []\n",
    "                pair_detailed[attempt_key] = {\n",
    "                    'predicted_grid_size': predicted_grid_size  # Add it to each attempt as well\n",
    "                }\n",
    "\n",
    "                # Run retries within the attempt\n",
    "                for retry in range(RETRY_ATTEMPTS):\n",
    "                    # Always plot in notebook\n",
    "                    should_plot = True\n",
    "                    logger.info(f\"Plot flag for task {task_id}, attempt {attempt}, retry {retry}: {should_plot}\")\n",
    "\n",
    "                    try:\n",
    "                        prediction_details = get_task_prediction(\n",
    "                            challenge_tasks=challenges,\n",
    "                            solutions=solutions,\n",
    "                            task_id=task_id,\n",
    "                            test_input_index=t,\n",
    "                            plot=should_plot\n",
    "                        )\n",
    "\n",
    "                        # Print prediction details for debugging\n",
    "                        print(f\"\\nPrediction details for {attempt_key}, retry {retry}:\")\n",
    "                        print(f\"Prediction: {prediction_details['prediction']}\")\n",
    "                        print(f\"Expected solution: {solutions[task_id][t]}\")\n",
    "\n",
    "                        # Store valid prediction and exit retry loop on success\n",
    "                        if prediction_details['prediction']:  # Only store if we have a prediction\n",
    "                            pair_attempts[attempt_key] = prediction_details['prediction']\n",
    "                            pair_detailed[attempt_key] = prediction_details\n",
    "                            \n",
    "                            # Check if prediction matches solution\n",
    "                            if prediction_details['prediction'] == solutions[task_id][t]:\n",
    "                                print(f\"Found correct solution in {attempt_key}, retry {retry}\")\n",
    "                                break\n",
    "                            \n",
    "                        break  # Exit retry loop if we got any valid prediction\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Retrying: {e}\")\n",
    "                        if retry == RETRY_ATTEMPTS - 1:\n",
    "                            pair_attempts[attempt_key] = []\n",
    "                            pair_detailed[attempt_key] = {'error': str(e)}\n",
    "\n",
    "            task_attempts.append(pair_attempts)\n",
    "            detailed_outputs[task_id].append(pair_detailed)\n",
    "\n",
    "        submission[task_id] = task_attempts\n",
    "\n",
    "        if NUM_TASKS is not None and i + 1 == NUM_TASKS:\n",
    "            break\n",
    "\n",
    "    # Save detailed outputs\n",
    "    serializable_outputs = make_serializable(detailed_outputs)\n",
    "    with open('detailed_outputs.json', 'w') as f:\n",
    "        json.dump(serializable_outputs, f, indent=2)\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating submission files and comparing it with solutions file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission file\n",
    "def create_submission_file(submission, file_name='submission.json'):\n",
    "    \"\"\"\n",
    "    Save a submission file to the specified file name\n",
    "    \"\"\"\n",
    "    with open(file_name, \"w\") as file:\n",
    "        json.dump(submission, file)\n",
    "\n",
    "    print (f\"Submission saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to compare submission with solutions\n",
    "def score_submission(submission_file_name, solutions) -> Tuple[float, int]:\n",
    "    \"\"\"\n",
    "    submission_file_name: str, the file name of your submission file\n",
    "    solutions: dict, the ground truth solutions you'd like to test against\n",
    "    \"\"\"\n",
    "    print(f\"Scoring {submission_file_name}\\n\")\n",
    "\n",
    "    # Open your submission file\n",
    "    with open(submission_file_name, \"r\") as file:\n",
    "        submission = json.load(file)\n",
    "\n",
    "    # Filter solutions to include only tasks in the submission\n",
    "    filtered_solutions = {task_id: solutions[task_id] for task_id in submission if task_id in solutions}\n",
    "\n",
    "    total_score = 0\n",
    "    total_tasks = 0\n",
    "\n",
    "    # Add debugging prints\n",
    "    #print(\"Solutions contents:\")\n",
    "    #print(json.dumps(filtered_solutions, indent=2))\n",
    "\n",
    "    # Loop through each task in your submission to grade it\n",
    "    for task_id, task_submission in submission.items():\n",
    "        if task_id not in filtered_solutions:\n",
    "            print(f\"Task {task_id} not found in solutions, skipping.\")\n",
    "            continue\n",
    "\n",
    "        total_tasks += 1\n",
    "        task_score = 0\n",
    "        num_pairs = len(task_submission)\n",
    "\n",
    "        print(f\"\\nScoring task {task_id}:\")\n",
    "        print(f\"Number of test pairs: {num_pairs}\")\n",
    "\n",
    "        # Go through each task. Most will only have 1\n",
    "        for pair_index, pair_attempts in enumerate(task_submission):\n",
    "            print(f\"\\nScoring Task {task_id} pair #{pair_index+1}\")\n",
    "            print(f\"Attempts available: {list(pair_attempts.keys())}\")\n",
    "            pair_correct = False\n",
    "\n",
    "            # Look at both of your attempts\n",
    "            for attempt_key, attempt in pair_attempts.items():\n",
    "                print(f\"\\nChecking {attempt_key}:\")\n",
    "                print(f\"Attempt solution: {attempt}\")\n",
    "                print(f\"Correct solution: {filtered_solutions[task_id][pair_index]}\")\n",
    "                \n",
    "                # check to see if one is correct\n",
    "                if attempt == filtered_solutions[task_id][pair_index]:\n",
    "                    print(f\"Task Id {task_id} pair {pair_index+1} {attempt_key} matches solution\")\n",
    "                    pair_correct = True\n",
    "                    break # If it is correct, log it and break the loop\n",
    "\n",
    "            if pair_correct:\n",
    "                task_score += 1\n",
    "                print(f\"Pair {pair_index+1} is correct\")\n",
    "            else:\n",
    "                print(f\"Pair {pair_index+1} is incorrect\")\n",
    "\n",
    "        task_score /= num_pairs\n",
    "        total_score += task_score\n",
    "        print(f\"\\nTask {task_id} score: {task_score}\")\n",
    "\n",
    "    final_score = {\n",
    "        'total_score': total_score,\n",
    "        'total_tasks_scored': total_tasks,\n",
    "        'percentage': round(total_score / total_tasks * 100, 2) if total_tasks > 0 else 0\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nFinal scoring results:\")\n",
    "    print(f\"Total score: {final_score['total_score']}\")\n",
    "    print(f\"Total tasks: {final_score['total_tasks_scored']}\")\n",
    "    print(f\"Percentage: {final_score['percentage']}%\")\n",
    "\n",
    "    return final_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The main function to bring everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(task_set='training', NUM_TASKS=None, submission_file_name='submission.json'):\n",
    "    # Load datasets\n",
    "    challenges, solutions = load_tasks_from_file(task_set=task_sets[task_set])\n",
    "\n",
    "    # Run the model, passing both challenges and solutions\n",
    "    submission = run_model(challenges, solutions, NUM_TASKS=NUM_TASKS)\n",
    "\n",
    "    # Create (and overwrite) a submission file\n",
    "    create_submission_file(submission, file_name=submission_file_name)\n",
    "\n",
    "    # Score the submission\n",
    "    score_result = score_submission(submission_file_name=submission_file_name, solutions=solutions)\n",
    "\n",
    "    logger.info(f\"Final score: {score_result['total_score']} of {score_result['total_tasks_scored']} ({round(score_result['total_score'] / score_result['total_tasks_scored'] * 100, 2)}%)\")\n",
    "\n",
    "    # Optionally, load and display detailed outputs\n",
    "    try:\n",
    "        with open('detailed_outputs.json', 'r') as f:\n",
    "            detailed_outputs = json.load(f)\n",
    "        # For example, print the detailed outputs\n",
    "        # print(json.dumps(detailed_outputs, indent=2))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading detailed outputs: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 21:51:13,704 - INFO - Starting task #1 (00576224), pair #1\n",
      "2024-12-22 21:51:13,705 - INFO - Plot flag for task 00576224, attempt 1, retry 0: True\n",
      "2024-12-22 21:51:13,707 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[8, 6],\n",
      "[6, 4],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],\n",
      "[6, 8, 6, 8, 6, 8],\n",
      "[4, 6, 4, 6, 4, 6],\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[7, 9],\n",
      "[4, 3],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],\n",
      "[9, 7, 9, 7, 9, 7],\n",
      "[3, 4, 3, 4, 3, 4],\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[3, 2]\n",
      "[7, 8]]\n",
      "\n",
      "Your Response: with predicted grid size: 6x6\n",
      "2024-12-22 21:51:16,406 - WARNING - Retrying: name 'llm_anthropic' is not defined\n",
      "2024-12-22 21:51:16,406 - INFO - Plot flag for task 00576224, attempt 1, retry 1: True\n",
      "2024-12-22 21:51:16,409 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[8, 6],\n",
      "[6, 4],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],\n",
      "[6, 8, 6, 8, 6, 8],\n",
      "[4, 6, 4, 6, 4, 6],\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[7, 9],\n",
      "[4, 3],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],\n",
      "[9, 7, 9, 7, 9, 7],\n",
      "[3, 4, 3, 4, 3, 4],\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[3, 2]\n",
      "[7, 8]]\n",
      "\n",
      "Your Response: with predicted grid size: 6x6\n",
      "2024-12-22 21:51:19,276 - WARNING - Retrying: name 'llm_anthropic' is not defined\n",
      "2024-12-22 21:51:19,277 - INFO - Plot flag for task 00576224, attempt 1, retry 2: True\n",
      "2024-12-22 21:51:19,278 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[8, 6],\n",
      "[6, 4],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],\n",
      "[6, 8, 6, 8, 6, 8],\n",
      "[4, 6, 4, 6, 4, 6],\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[7, 9],\n",
      "[4, 3],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],\n",
      "[9, 7, 9, 7, 9, 7],\n",
      "[3, 4, 3, 4, 3, 4],\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[3, 2]\n",
      "[7, 8]]\n",
      "\n",
      "Your Response: with predicted grid size: 6x6\n",
      "2024-12-22 21:51:22,288 - WARNING - Retrying: name 'llm_anthropic' is not defined\n",
      "2024-12-22 21:51:22,289 - INFO - Plot flag for task 00576224, attempt 2, retry 0: True\n",
      "2024-12-22 21:51:22,290 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[8, 6],\n",
      "[6, 4],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],\n",
      "[6, 8, 6, 8, 6, 8],\n",
      "[4, 6, 4, 6, 4, 6],\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[7, 9],\n",
      "[4, 3],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],\n",
      "[9, 7, 9, 7, 9, 7],\n",
      "[3, 4, 3, 4, 3, 4],\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[3, 2]\n",
      "[7, 8]]\n",
      "\n",
      "Your Response: with predicted grid size: 6x6\n",
      "2024-12-22 21:51:27,691 - WARNING - Retrying: name 'llm_anthropic' is not defined\n",
      "2024-12-22 21:51:27,691 - INFO - Plot flag for task 00576224, attempt 2, retry 1: True\n",
      "2024-12-22 21:51:27,694 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[8, 6],\n",
      "[6, 4],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],\n",
      "[6, 8, 6, 8, 6, 8],\n",
      "[4, 6, 4, 6, 4, 6],\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[7, 9],\n",
      "[4, 3],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],\n",
      "[9, 7, 9, 7, 9, 7],\n",
      "[3, 4, 3, 4, 3, 4],\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[3, 2]\n",
      "[7, 8]]\n",
      "\n",
      "Your Response: with predicted grid size: 6x6\n",
      "2024-12-22 21:51:30,384 - WARNING - Retrying: name 'llm_anthropic' is not defined\n",
      "2024-12-22 21:51:30,386 - INFO - Plot flag for task 00576224, attempt 2, retry 2: True\n",
      "2024-12-22 21:51:30,389 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[8, 6],\n",
      "[6, 4],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],\n",
      "[6, 8, 6, 8, 6, 8],\n",
      "[4, 6, 4, 6, 4, 6],\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[7, 9],\n",
      "[4, 3],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],\n",
      "[9, 7, 9, 7, 9, 7],\n",
      "[3, 4, 3, 4, 3, 4],\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[3, 2]\n",
      "[7, 8]]\n",
      "\n",
      "Your Response: with predicted grid size: 6x6\n",
      "2024-12-22 21:51:33,727 - WARNING - Retrying: name 'llm_anthropic' is not defined\n",
      "2024-12-22 21:51:33,729 - INFO - Starting task #2 (17cae0c1), pair #1\n",
      "2024-12-22 21:51:33,730 - INFO - Plot flag for task 17cae0c1, attempt 1, retry 0: True\n",
      "2024-12-22 21:51:33,733 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[5, 5, 5, 0, 0, 0, 0, 0, 5],\n",
      "[5, 0, 5, 0, 5, 0, 0, 5, 0],\n",
      "[5, 5, 5, 0, 0, 0, 5, 0, 0],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[0, 0, 5, 0, 0, 0, 0, 0, 0],\n",
      "[0, 5, 0, 0, 0, 0, 0, 5, 0],\n",
      "[5, 0, 0, 5, 5, 5, 0, 0, 0],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],]\n",
      "\n",
      "Example 3: Input\n",
      "[\n",
      "[5, 5, 5, 5, 5, 5, 0, 0, 0],\n",
      "[0, 0, 0, 5, 0, 5, 0, 0, 0],\n",
      "[0, 0, 0, 5, 5, 5, 5, 5, 5],]\n",
      "\n",
      "Example 3: Output\n",
      "[\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],]\n",
      "\n",
      "Example 4: Input\n",
      "[\n",
      "[0, 0, 0, 5, 5, 5, 5, 5, 5],\n",
      "[0, 5, 0, 0, 0, 0, 5, 0, 5],\n",
      "[0, 0, 0, 0, 0, 0, 5, 5, 5],]\n",
      "\n",
      "Example 4: Output\n",
      "[\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[0, 0, 0, 0, 0, 5, 5, 5, 5]\n",
      "[0, 0, 0, 0, 5, 0, 0, 0, 0]\n",
      "[5, 5, 5, 5, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Your Response: with predicted grid size: 9x3\n",
      "2024-12-22 21:51:37,444 - WARNING - Retrying: name 'llm_anthropic' is not defined\n",
      "2024-12-22 21:51:37,445 - INFO - Plot flag for task 17cae0c1, attempt 1, retry 1: True\n",
      "2024-12-22 21:51:37,447 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[5, 5, 5, 0, 0, 0, 0, 0, 5],\n",
      "[5, 0, 5, 0, 5, 0, 0, 5, 0],\n",
      "[5, 5, 5, 0, 0, 0, 5, 0, 0],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[0, 0, 5, 0, 0, 0, 0, 0, 0],\n",
      "[0, 5, 0, 0, 0, 0, 0, 5, 0],\n",
      "[5, 0, 0, 5, 5, 5, 0, 0, 0],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],]\n",
      "\n",
      "Example 3: Input\n",
      "[\n",
      "[5, 5, 5, 5, 5, 5, 0, 0, 0],\n",
      "[0, 0, 0, 5, 0, 5, 0, 0, 0],\n",
      "[0, 0, 0, 5, 5, 5, 5, 5, 5],]\n",
      "\n",
      "Example 3: Output\n",
      "[\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],]\n",
      "\n",
      "Example 4: Input\n",
      "[\n",
      "[0, 0, 0, 5, 5, 5, 5, 5, 5],\n",
      "[0, 5, 0, 0, 0, 0, 5, 0, 5],\n",
      "[0, 0, 0, 0, 0, 0, 5, 5, 5],]\n",
      "\n",
      "Example 4: Output\n",
      "[\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[0, 0, 0, 0, 0, 5, 5, 5, 5]\n",
      "[0, 0, 0, 0, 5, 0, 0, 0, 0]\n",
      "[5, 5, 5, 5, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Your Response: with predicted grid size: 9x3\n",
      "2024-12-22 21:51:40,898 - WARNING - Retrying: name 'llm_anthropic' is not defined\n",
      "2024-12-22 21:51:40,899 - INFO - Plot flag for task 17cae0c1, attempt 1, retry 2: True\n",
      "2024-12-22 21:51:40,901 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[5, 5, 5, 0, 0, 0, 0, 0, 5],\n",
      "[5, 0, 5, 0, 5, 0, 0, 5, 0],\n",
      "[5, 5, 5, 0, 0, 0, 5, 0, 0],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[0, 0, 5, 0, 0, 0, 0, 0, 0],\n",
      "[0, 5, 0, 0, 0, 0, 0, 5, 0],\n",
      "[5, 0, 0, 5, 5, 5, 0, 0, 0],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],]\n",
      "\n",
      "Example 3: Input\n",
      "[\n",
      "[5, 5, 5, 5, 5, 5, 0, 0, 0],\n",
      "[0, 0, 0, 5, 0, 5, 0, 0, 0],\n",
      "[0, 0, 0, 5, 5, 5, 5, 5, 5],]\n",
      "\n",
      "Example 3: Output\n",
      "[\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],]\n",
      "\n",
      "Example 4: Input\n",
      "[\n",
      "[0, 0, 0, 5, 5, 5, 5, 5, 5],\n",
      "[0, 5, 0, 0, 0, 0, 5, 0, 5],\n",
      "[0, 0, 0, 0, 0, 0, 5, 5, 5],]\n",
      "\n",
      "Example 4: Output\n",
      "[\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[0, 0, 0, 0, 0, 5, 5, 5, 5]\n",
      "[0, 0, 0, 0, 5, 0, 0, 0, 0]\n",
      "[5, 5, 5, 5, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Your Response: with predicted grid size: 9x3\n",
      "2024-12-22 21:51:48,328 - WARNING - Retrying: name 'llm_anthropic' is not defined\n",
      "2024-12-22 21:51:48,329 - INFO - Plot flag for task 17cae0c1, attempt 2, retry 0: True\n",
      "2024-12-22 21:51:48,331 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[5, 5, 5, 0, 0, 0, 0, 0, 5],\n",
      "[5, 0, 5, 0, 5, 0, 0, 5, 0],\n",
      "[5, 5, 5, 0, 0, 0, 5, 0, 0],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[0, 0, 5, 0, 0, 0, 0, 0, 0],\n",
      "[0, 5, 0, 0, 0, 0, 0, 5, 0],\n",
      "[5, 0, 0, 5, 5, 5, 0, 0, 0],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],]\n",
      "\n",
      "Example 3: Input\n",
      "[\n",
      "[5, 5, 5, 5, 5, 5, 0, 0, 0],\n",
      "[0, 0, 0, 5, 0, 5, 0, 0, 0],\n",
      "[0, 0, 0, 5, 5, 5, 5, 5, 5],]\n",
      "\n",
      "Example 3: Output\n",
      "[\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],]\n",
      "\n",
      "Example 4: Input\n",
      "[\n",
      "[0, 0, 0, 5, 5, 5, 5, 5, 5],\n",
      "[0, 5, 0, 0, 0, 0, 5, 0, 5],\n",
      "[0, 0, 0, 0, 0, 0, 5, 5, 5],]\n",
      "\n",
      "Example 4: Output\n",
      "[\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[0, 0, 0, 0, 0, 5, 5, 5, 5]\n",
      "[0, 0, 0, 0, 5, 0, 0, 0, 0]\n",
      "[5, 5, 5, 5, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Your Response: with predicted grid size: 9x3\n",
      "2024-12-22 21:51:52,367 - WARNING - Retrying: name 'llm_anthropic' is not defined\n",
      "2024-12-22 21:51:52,369 - INFO - Plot flag for task 17cae0c1, attempt 2, retry 1: True\n",
      "2024-12-22 21:51:52,372 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[5, 5, 5, 0, 0, 0, 0, 0, 5],\n",
      "[5, 0, 5, 0, 5, 0, 0, 5, 0],\n",
      "[5, 5, 5, 0, 0, 0, 5, 0, 0],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[0, 0, 5, 0, 0, 0, 0, 0, 0],\n",
      "[0, 5, 0, 0, 0, 0, 0, 5, 0],\n",
      "[5, 0, 0, 5, 5, 5, 0, 0, 0],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],]\n",
      "\n",
      "Example 3: Input\n",
      "[\n",
      "[5, 5, 5, 5, 5, 5, 0, 0, 0],\n",
      "[0, 0, 0, 5, 0, 5, 0, 0, 0],\n",
      "[0, 0, 0, 5, 5, 5, 5, 5, 5],]\n",
      "\n",
      "Example 3: Output\n",
      "[\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],]\n",
      "\n",
      "Example 4: Input\n",
      "[\n",
      "[0, 0, 0, 5, 5, 5, 5, 5, 5],\n",
      "[0, 5, 0, 0, 0, 0, 5, 0, 5],\n",
      "[0, 0, 0, 0, 0, 0, 5, 5, 5],]\n",
      "\n",
      "Example 4: Output\n",
      "[\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[0, 0, 0, 0, 0, 5, 5, 5, 5]\n",
      "[0, 0, 0, 0, 5, 0, 0, 0, 0]\n",
      "[5, 5, 5, 5, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Your Response: with predicted grid size: 9x3\n",
      "2024-12-22 21:51:55,879 - WARNING - Retrying: name 'llm_anthropic' is not defined\n",
      "2024-12-22 21:51:55,881 - INFO - Plot flag for task 17cae0c1, attempt 2, retry 2: True\n",
      "2024-12-22 21:51:55,884 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[5, 5, 5, 0, 0, 0, 0, 0, 5],\n",
      "[5, 0, 5, 0, 5, 0, 0, 5, 0],\n",
      "[5, 5, 5, 0, 0, 0, 5, 0, 0],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],\n",
      "[3, 3, 3, 4, 4, 4, 9, 9, 9],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[0, 0, 5, 0, 0, 0, 0, 0, 0],\n",
      "[0, 5, 0, 0, 0, 0, 0, 5, 0],\n",
      "[5, 0, 0, 5, 5, 5, 0, 0, 0],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],\n",
      "[9, 9, 9, 1, 1, 1, 4, 4, 4],]\n",
      "\n",
      "Example 3: Input\n",
      "[\n",
      "[5, 5, 5, 5, 5, 5, 0, 0, 0],\n",
      "[0, 0, 0, 5, 0, 5, 0, 0, 0],\n",
      "[0, 0, 0, 5, 5, 5, 5, 5, 5],]\n",
      "\n",
      "Example 3: Output\n",
      "[\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],\n",
      "[6, 6, 6, 3, 3, 3, 1, 1, 1],]\n",
      "\n",
      "Example 4: Input\n",
      "[\n",
      "[0, 0, 0, 5, 5, 5, 5, 5, 5],\n",
      "[0, 5, 0, 0, 0, 0, 5, 0, 5],\n",
      "[0, 0, 0, 0, 0, 0, 5, 5, 5],]\n",
      "\n",
      "Example 4: Output\n",
      "[\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],\n",
      "[4, 4, 4, 6, 6, 6, 3, 3, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[0, 0, 0, 0, 0, 5, 5, 5, 5]\n",
      "[0, 0, 0, 0, 5, 0, 0, 0, 0]\n",
      "[5, 5, 5, 5, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Your Response: with predicted grid size: 9x3\n",
      "2024-12-22 21:51:58,445 - WARNING - Retrying: name 'llm_anthropic' is not defined\n",
      "2024-12-22 21:51:58,446 - INFO - Starting task #3 (2072aba6), pair #1\n",
      "2024-12-22 21:51:58,447 - INFO - Plot flag for task 2072aba6, attempt 1, retry 0: True\n",
      "2024-12-22 21:51:58,448 - INFO - Identifying logic for task: Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[0, 5, 0],\n",
      "[5, 5, 5],\n",
      "[0, 5, 0],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[0, 0, 1, 2, 0, 0],\n",
      "[0, 0, 2, 1, 0, 0],\n",
      "[1, 2, 1, 2, 1, 2],\n",
      "[2, 1, 2, 1, 2, 1],\n",
      "[0, 0, 1, 2, 0, 0],\n",
      "[0, 0, 2, 1, 0, 0],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[5, 0, 0],\n",
      "[0, 5, 0],\n",
      "[0, 0, 5],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[1, 2, 0, 0, 0, 0],\n",
      "[2, 1, 0, 0, 0, 0],\n",
      "[0, 0, 1, 2, 0, 0],\n",
      "[0, 0, 2, 1, 0, 0],\n",
      "[0, 0, 0, 0, 1, 2],\n",
      "[0, 0, 0, 0, 2, 1],]\n",
      "\n",
      "Example 3: Input\n",
      "[\n",
      "[0, 5, 0],\n",
      "[0, 5, 5],\n",
      "[5, 5, 0],]\n",
      "\n",
      "Example 3: Output\n",
      "[\n",
      "[0, 0, 1, 2, 0, 0],\n",
      "[0, 0, 2, 1, 0, 0],\n",
      "[0, 0, 1, 2, 1, 2],\n",
      "[0, 0, 2, 1, 2, 1],\n",
      "[1, 2, 1, 2, 0, 0],\n",
      "[2, 1, 2, 1, 0, 0],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[0, 0, 0]\n",
      "[0, 5, 0]\n",
      "[5, 5, 5]]\n",
      "\n",
      "Your Response: with predicted grid size: 6x6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main(task_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m'\u001b[39m, NUM_TASKS\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m)\n",
      "Cell \u001b[0;32mIn[66], line 6\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(task_set, NUM_TASKS, submission_file_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m challenges, solutions \u001b[38;5;241m=\u001b[39m load_tasks_from_file(task_set\u001b[38;5;241m=\u001b[39mtask_sets[task_set])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Run the model, passing both challenges and solutions\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m submission \u001b[38;5;241m=\u001b[39m run_model(challenges, solutions, NUM_TASKS\u001b[38;5;241m=\u001b[39mNUM_TASKS)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create (and overwrite) a submission file\u001b[39;00m\n\u001b[1;32m      9\u001b[0m create_submission_file(submission, file_name\u001b[38;5;241m=\u001b[39msubmission_file_name)\n",
      "Cell \u001b[0;32mIn[63], line 50\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(challenges, solutions, NUM_ATTEMPTS, RETRY_ATTEMPTS, NUM_TASKS)\u001b[0m\n\u001b[1;32m     47\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlot flag for task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, attempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, retry \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshould_plot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     prediction_details \u001b[38;5;241m=\u001b[39m get_task_prediction(\n\u001b[1;32m     51\u001b[0m         challenge_tasks\u001b[38;5;241m=\u001b[39mchallenges,\n\u001b[1;32m     52\u001b[0m         solutions\u001b[38;5;241m=\u001b[39msolutions,\n\u001b[1;32m     53\u001b[0m         task_id\u001b[38;5;241m=\u001b[39mtask_id,\n\u001b[1;32m     54\u001b[0m         test_input_index\u001b[38;5;241m=\u001b[39mt,\n\u001b[1;32m     55\u001b[0m         plot\u001b[38;5;241m=\u001b[39mshould_plot\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Print prediction details for debugging\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPrediction details for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, retry \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[62], line 29\u001b[0m, in \u001b[0;36mget_task_prediction\u001b[0;34m(challenge_tasks, solutions, task_id, test_input_index, plot)\u001b[0m\n\u001b[1;32m     16\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask_string\u001b[39m\u001b[38;5;124m'\u001b[39m: task_string,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask_data\u001b[39m\u001b[38;5;124m'\u001b[39m: task_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m: []\n\u001b[1;32m     26\u001b[0m }\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Invoke the graph or prediction model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m final_state \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39minvoke(initial_state)\n\u001b[1;32m     30\u001b[0m predicted_solution \u001b[38;5;241m=\u001b[39m final_state\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Add debugging print statements\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1545\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1545\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1547\u001b[0m     config,\n\u001b[1;32m   1548\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1549\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1550\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1551\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1552\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1554\u001b[0m ):\n\u001b[1;32m   1555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1556\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1278\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1273\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   1274\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   1275\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   1276\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1277\u001b[0m     ):\n\u001b[0;32m-> 1278\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1279\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1280\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1281\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1282\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1283\u001b[0m         ):\n\u001b[1;32m   1284\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/pregel/runner.py:52\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m     50\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     run_with_retry(t, retry_policy)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/pregel/retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/utils/runnable.py:385\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/utils/runnable.py:167\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 167\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[60], line 307\u001b[0m, in \u001b[0;36midentify_logic\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    285\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[1;32m    286\u001b[0m     template\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an AI assistant specializing in puzzle solving.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_string\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_grid_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    304\u001b[0m )\n\u001b[1;32m    306\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm_openai\n\u001b[0;32m--> 307\u001b[0m output \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_string\u001b[39m\u001b[38;5;124m\"\u001b[39m: task_string,\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_grid_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: predicted_grid_size\n\u001b[1;32m    310\u001b[0m })\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# Return both the AIMessage and the predicted_grid_size\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [AIMessage(content\u001b[38;5;241m=\u001b[39moutput)],\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_grid_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: predicted_grid_size  \u001b[38;5;66;03m# Include this in the return\u001b[39;00m\n\u001b[1;32m    316\u001b[0m }\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langchain_core/runnables/base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3021\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    285\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    286\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    287\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    288\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    289\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    290\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    291\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    292\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    293\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:784\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    778\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    782\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    783\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:641\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    640\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 641\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    642\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    643\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    645\u001b[0m ]\n\u001b[1;32m    646\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:631\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    630\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 631\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[1;32m    632\u001b[0m                 m,\n\u001b[1;32m    633\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    634\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    635\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    636\u001b[0m             )\n\u001b[1;32m    637\u001b[0m         )\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:853\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 853\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m    854\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    855\u001b[0m         )\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:670\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py:704\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    703\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    705\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    706\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    707\u001b[0m             {\n\u001b[1;32m    708\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    709\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    710\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    711\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    712\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    713\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    714\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m    715\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m    716\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    717\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    718\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m    719\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    720\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    721\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    722\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m    723\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    724\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    725\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m    726\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    727\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    728\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    729\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    730\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    731\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    732\u001b[0m             },\n\u001b[1;32m    733\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    734\u001b[0m         ),\n\u001b[1;32m    735\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    736\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    737\u001b[0m         ),\n\u001b[1;32m    738\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    739\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    740\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    741\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1268\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1256\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1264\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1265\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1266\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1267\u001b[0m     )\n\u001b[0;32m-> 1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:945\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    943\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 945\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    946\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    947\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    948\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    949\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    950\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m    951\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:981\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    978\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 981\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m    982\u001b[0m         request,\n\u001b[1;32m    983\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    985\u001b[0m     )\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    987\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(task_set='evaluation', NUM_TASKS=28)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
