{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "from glob import glob\n",
    "\n",
    "# LangChain and related imports\n",
    "import langchain  # Main LangChain import\n",
    "from langchain_openai import ChatOpenAI  # To work with OpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser  # To help with structured output\n",
    "from langchain_core.prompts import PromptTemplate  # To help create our prompt\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field  # To help with defining what output structure we want\n",
    "\n",
    "# Pydantic import (no need to import twice)\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Typing and annotations\n",
    "from typing import List, Tuple, Dict\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load JSON files\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Reading files\n",
    "base_path = 'arc-agi-genesis/data/challenges/'\n",
    "training_challenges =  load_json(base_path + 'arc-agi_training_challenges.json')\n",
    "training_solutions =   load_json(base_path + 'arc-agi_training_solutions.json')\n",
    "\n",
    "evaluation_challenges = load_json(base_path + 'arc-agi_evaluation_challenges.json')\n",
    "evaluation_solutions = load_json(base_path + 'arc-agi_evaluation_solutions.json')\n",
    "\n",
    "test_challenges =  load_json(base_path + 'arc-agi_test_challenges.json')\n",
    "\n",
    "task_sets = {\n",
    "    'training': {\n",
    "        'challenges': training_challenges,\n",
    "        'solutions': training_solutions,\n",
    "    },\n",
    "    'evaluation': {\n",
    "        'challenges': evaluation_challenges,\n",
    "        'solutions': evaluation_solutions,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Updated function to load tasks from a pre-loaded task set\n",
    "def load_tasks_from_file(task_set):\n",
    "    \"\"\"\n",
    "    Loads the tasks from the pre-loaded JSON data and returns the challenges and solutions tasks.\n",
    "    \"\"\"\n",
    "    challenges = task_set['challenges']\n",
    "    solutions = task_set['solutions']\n",
    "\n",
    "    return challenges, solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training challenges = 400\n",
      "Number of solutions of training challenges = 400\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training challenges = {len(training_challenges)}')\n",
    "print(f'Number of solutions of training challenges = {len(training_solutions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': [{'input': [[1, 0, 1, 5, 1, 0, 1], [0, 1, 0, 5, 1, 0, 1], [1, 0, 1, 5, 0, 1, 0]]}], 'train': [{'input': [[1, 0, 0, 5, 0, 1, 0], [0, 1, 0, 5, 1, 1, 1], [1, 0, 0, 5, 0, 0, 0]], 'output': [[0, 0, 0], [0, 2, 0], [0, 0, 0]]}, {'input': [[1, 1, 0, 5, 0, 1, 0], [0, 0, 1, 5, 1, 1, 1], [1, 1, 0, 5, 0, 1, 0]], 'output': [[0, 2, 0], [0, 0, 2], [0, 2, 0]]}, {'input': [[0, 0, 1, 5, 0, 0, 0], [1, 1, 0, 5, 1, 0, 1], [0, 1, 1, 5, 1, 0, 1]], 'output': [[0, 0, 0], [2, 0, 0], [0, 0, 2]]}]}\n"
     ]
    }
   ],
   "source": [
    "# Loading tasks from the 'training' task set\n",
    "challenges, solutions = load_tasks_from_file(task_set=task_sets['training'])\n",
    "print(challenges['0520fde7'])  # Accessing a specific challenge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initializing LLM client to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('api.env')\n",
    "\n",
    "# Get the OpenAI API key from environment variables\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize the ChatOpenAI model with the API key\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', openai_api_key=openai_api_key, max_tokens=3000)\n",
    "\n",
    "## And incase you want to try Anthropic\n",
    "# llm = ChatAnthropic(model='claude-3-5-sonnet-20240620', api_key=UserSecretsClient().get_secret(\"ANTHROPIC_API_KEY\"), max_tokens=3000)\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=UserSecretsClient().get_secret(\"GOOGLE_API_KEY\"), max_tokens=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to make MVP product which is just regular openai model trying to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting train and test pairs to a string format ideal for LLMs\n",
    "def json_task_to_string(challenge_tasks: dict, task_id: str, test_input_index: int) -> str:\n",
    "    \"\"\"\n",
    "    challenge_tasks: dict a list of tasks\n",
    "    task_id: str the id of the task we want to convert to a string\n",
    "    \n",
    "    Convert your json task into a string so you can pass it to your LLM.\n",
    "    This is a crucial step where you can use your creativity to edit how tasks are represented.\n",
    "    \"\"\"\n",
    "    json_task = challenge_tasks[task_id]\n",
    "\n",
    "    final_output = \"\"\n",
    "\n",
    "    train_tasks = json_task['train']\n",
    "    test_task = json_task['test']\n",
    "\n",
    "    final_output = \"Training Examples\\n\"\n",
    "\n",
    "    for i, task in enumerate(train_tasks):\n",
    "        final_output += f\"Example {i + 1}: Input\\n[\"\n",
    "        for row in task['input']:\n",
    "            final_output += f\"\\n{str(row)},\"\n",
    "\n",
    "        final_output += \"]\\n\\n\"\n",
    "        final_output += f\"Example {i + 1}: Output\\n[\"\n",
    "\n",
    "        for row in task['output']:\n",
    "            final_output += f\"\\n{str(row)},\"\n",
    "\n",
    "        final_output += \"]\\n\\n\"\n",
    "\n",
    "    final_output += \"Test\\n[\"\n",
    "    for row in test_task[test_input_index]['input']:\n",
    "        final_output += f\"\\n{str(row)}\"\n",
    "\n",
    "    final_output += \"]\\n\\nYour Response:\"\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[1, 0, 0, 5, 0, 1, 0],\n",
      "[0, 1, 0, 5, 1, 1, 1],\n",
      "[1, 0, 0, 5, 0, 0, 0],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[0, 0, 0],\n",
      "[0, 2, 0],\n",
      "[0, 0, 0],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[1, 1, 0, 5, 0, 1, 0],\n",
      "[0, 0, 1, 5, 1, 1, 1],\n",
      "[1, 1, 0, 5, 0, 1, 0],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[0, 2, 0],\n",
      "[0, 0, 2],\n",
      "[0, 2, 0],]\n",
      "\n",
      "Example 3: Input\n",
      "[\n",
      "[0, 0, 1, 5, 0, 0, 0],\n",
      "[1, 1, 0, 5, 1, 0, 1],\n",
      "[0, 1, 1, 5, 1, 0, 1],]\n",
      "\n",
      "Example 3: Output\n",
      "[\n",
      "[0, 0, 0],\n",
      "[2, 0, 0],\n",
      "[0, 0, 2],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[1, 0, 1, 5, 1, 0, 1]\n",
      "[0, 1, 0, 5, 1, 0, 1]\n",
      "[1, 0, 1, 5, 0, 1, 0]]\n",
      "\n",
      "Your Response:\n"
     ]
    }
   ],
   "source": [
    "# an example of how the function works\n",
    "task_string = json_task_to_string(challenges, '0520fde7', 0)\n",
    "print (task_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a json output parser to parse the output, since LLMs aren't perfect at generating valid json\n",
    "# Defining a prediction as a list of lists\n",
    "class ARCPrediction(BaseModel):\n",
    "    prediction: List[List] = Field(..., description=\"A prediction for a task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating function to get task prediction, make prompt, make API calls to model and parse output with retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Dict\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "\n",
    "\n",
    "# Define the ARCPrediction model (with an empty default list)\n",
    "class ARCPrediction(BaseModel):\n",
    "    prediction: List[List[int]] = Field(default_factory=list, description=\"A prediction for a task\")\n",
    "\n",
    "# output parser to parse the output\n",
    "from typing import Any, Dict\n",
    "\n",
    "class JsonOutputParser:\n",
    "    def __init__(self, pydantic_object: BaseModel):\n",
    "        self.pydantic_object = pydantic_object\n",
    "\n",
    "    def get_format_instructions(self):\n",
    "        return f\"Ensure the output is a valid JSON format with a structure matching {self.pydantic_object.schema()}\"\n",
    "\n",
    "    def parse(self, output: Any):\n",
    "        try:\n",
    "            # If output is a dict, extract the 'content' field\n",
    "            if isinstance(output, dict) and 'content' in output:\n",
    "                output = output['content']\n",
    "            \n",
    "            # Strip backticks, newlines, and other extraneous markdown elements\n",
    "            output = re.sub(r\"```(?:json)?|[\\n\\r]\", \"\", output).strip()\n",
    "            \n",
    "            # If the output is already a valid JSON string, parse it directly\n",
    "            try:\n",
    "                parsed_output = json.loads(output)\n",
    "            except json.JSONDecodeError:\n",
    "                # If not, try to extract a JSON-like structure\n",
    "                match = re.search(r'\\[.*\\]', output, re.DOTALL)\n",
    "                if match:\n",
    "                    output = match.group(0)\n",
    "                parsed_output = json.loads(output)\n",
    "            \n",
    "            if isinstance(parsed_output, list):\n",
    "                return self.pydantic_object(prediction=parsed_output)\n",
    "            elif isinstance(parsed_output, dict) and 'prediction' in parsed_output:\n",
    "                return self.pydantic_object.parse_obj(parsed_output)\n",
    "            else:\n",
    "                raise ValueError(f\"Missing 'prediction' field in output: {output}\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Invalid JSON output: {output}\") from e\n",
    "\n",
    "    def __call__(self, output: Any):\n",
    "        return self.parse(output)\n",
    "\n",
    "\n",
    "# Define the State\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    challenge_tasks: Dict\n",
    "    task_id: str\n",
    "    test_input_index: int\n",
    "    task_string: str\n",
    "    prediction: List[List[int]]\n",
    "    validation_passed: bool\n",
    "    retry_count: int\n",
    "\n",
    "\n",
    "# Create the graph builder\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "# Node to prepare the task string\n",
    "def prepare_task(state: State):\n",
    "    task_string = json_task_to_string(\n",
    "        state[\"challenge_tasks\"], state[\"task_id\"], state[\"test_input_index\"]\n",
    "    )\n",
    "    return {\"task_string\": task_string, \"retry_count\": 0}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"prepare_task\", prepare_task)\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "def solve_task(state: State):\n",
    "    parser = JsonOutputParser(pydantic_object=ARCPrediction)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. \"\n",
    "                \"Identify the pattern, then apply that pattern to the test input to give a final output. \"\n",
    "                \"Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. \"\n",
    "                \"{task_string}\\n\",\n",
    "        input_variables=[\"task_string\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "    # Build the chain with callable parser\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    logging.debug(f\"Prompt: {prompt.format(task_string=state['task_string'])}\")\n",
    "    \n",
    "    raw_output = chain.invoke({\"task_string\": state[\"task_string\"]})\n",
    "    logging.debug(f\"Raw LLM output: {raw_output}\")\n",
    "\n",
    "    output = parser(raw_output)\n",
    "    logging.debug(f\"Parsed output: {output}\")\n",
    "\n",
    "    prediction = output.prediction if isinstance(output, ARCPrediction) else output\n",
    "\n",
    "    return {\"prediction\": prediction}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"solve_task\", solve_task)\n",
    "\n",
    "\n",
    "# Node to validate the output\n",
    "def validate_output(state: State):\n",
    "    prediction = state[\"prediction\"]\n",
    "    if all(\n",
    "        isinstance(sublist, list) and all(isinstance(item, int) for item in sublist)\n",
    "        for sublist in prediction\n",
    "    ):\n",
    "        return {\"validation_passed\": True}\n",
    "    else:\n",
    "        print(\"Warning: Output must be a list of lists of integers.\")\n",
    "        print(f\"Errored Output: {prediction}\")\n",
    "        return {\"validation_passed\": False}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"validate_output\", validate_output)\n",
    "\n",
    "\n",
    "# Node to retry solving the task\n",
    "def retry_solve(state: State):\n",
    "    MAX_RETRIES = 2\n",
    "    retry_count = state.get(\"retry_count\", 0) + 1\n",
    "    if retry_count > MAX_RETRIES:\n",
    "        print(\"Maximum retries reached.\")\n",
    "        return {\"retry_count\": retry_count, \"validation_passed\": False}\n",
    "    else:\n",
    "        parser = JsonOutputParser(pydantic_object=ARCPrediction)\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. \"\n",
    "                     \"Identify the pattern, then apply that pattern to the test input to give a final output. \"\n",
    "                     \"Your previous attempt was: {previous_prediction} \"\n",
    "                     \"Just give valid json list of lists response back, nothing else. Do not explain your thoughts. \"\n",
    "                     \"{format_instructions}\\n{task_string}\\n\",\n",
    "            input_variables=[\"task_string\", \"previous_prediction\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        # Build the chain with callable parser instead of direct use\n",
    "        chain = prompt | llm | parser\n",
    "\n",
    "        output = chain.invoke({\n",
    "            \"task_string\": state[\"task_string\"],\n",
    "            \"previous_prediction\": state[\"prediction\"]\n",
    "        })\n",
    "\n",
    "        if isinstance(output, dict):\n",
    "            prediction = output.get('prediction', output)\n",
    "        else:\n",
    "            prediction = output\n",
    "\n",
    "        return {\"prediction\": prediction, \"retry_count\": retry_count}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"retry_solve\", retry_solve)\n",
    "\n",
    "\n",
    "# Conditional edge to decide the next node based on validation\n",
    "def check_validation(state: State):\n",
    "    if state.get(\"validation_passed\"):\n",
    "        return END\n",
    "    else:\n",
    "        retry_count = state.get(\"retry_count\", 0)\n",
    "        if retry_count >= 2:\n",
    "            return END\n",
    "        else:\n",
    "            return \"retry_solve\"\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"validate_output\",\n",
    "    check_validation,\n",
    "    {END: END, \"retry_solve\": \"retry_solve\"}\n",
    ")\n",
    "\n",
    "\n",
    "# Add edges between nodes\n",
    "graph_builder.add_edge(START, \"prepare_task\")\n",
    "graph_builder.add_edge(\"prepare_task\", \"solve_task\")\n",
    "graph_builder.add_edge(\"solve_task\", \"validate_output\")\n",
    "graph_builder.add_edge(\"retry_solve\", \"validate_output\")\n",
    "\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "\n",
    "# Function to get the task prediction using the graph\n",
    "def get_task_prediction(challenge_tasks, task_id, test_input_index) -> List[List[int]]:\n",
    "    initial_state = {\n",
    "        \"challenge_tasks\": challenge_tasks,\n",
    "        \"task_id\": task_id,\n",
    "        \"test_input_index\": test_input_index,\n",
    "        \"messages\": []\n",
    "    }\n",
    "    # Run the graph\n",
    "    state = graph.invoke(initial_state)\n",
    "\n",
    "    prediction = state.get(\"prediction\")\n",
    "\n",
    "    if not all(\n",
    "        isinstance(sublist, list) and all(isinstance(item, int) for item in sublist)\n",
    "        for sublist in prediction\n",
    "    ):\n",
    "        print(\"Warning: Output must be a list of lists of integers.\")\n",
    "        print(f\"Errored Output: {prediction}\")\n",
    "        raise ValueError(\"Output must be a list of lists of integers.\")\n",
    "\n",
    "    # Output the prediction grid size\n",
    "    num_rows = len(prediction)\n",
    "    num_cols = len(prediction[0]) if num_rows > 0 else 0\n",
    "    print(f\"    Prediction Grid Size: {num_rows}x{num_cols}\\n\")\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(challenges, NUM_ATTEMPTS=2, RETRY_ATTEMPTS=3, NUM_TASKS=None):\n",
    "    \"\"\"\n",
    "    challenges: dict a list of challenges. This should come directly from your _challenges file\n",
    "    NUM_ATTEMPTS: int the number of times to attempt a prediction. The official competition has 2 attempts.\n",
    "    RETRY_ATTEMPTS: int the number of times to retry a prediction if it fails\n",
    "    NUM_TASKS: int, If set, this represents the the number of tasks you'd like to test. If None then the all challeneges will be tested\n",
    "\n",
    "    Loop through your challenges and produce a submission.json file you can submit for a score.\n",
    "    \"\"\"\n",
    "\n",
    "    # A dict to hold your submissions that you'll return after all predictions are made\n",
    "    submission = {}\n",
    "\n",
    "    # Run through each task in your challenge set\n",
    "    for i, task_id in enumerate(challenges):\n",
    "        task_attempts = []  # List to store all attempts for the current task\n",
    "\n",
    "        # Go through each test pair to get a prediction. 96% of challenges have 1 pair.\n",
    "        for t, pair in enumerate(challenges[task_id]['test']):\n",
    "            print(f\"Starting task #{i + 1} ({task_id}), pair #{t+1}\")\n",
    "\n",
    "            # Dictionary to store attempts for the current test pair\n",
    "            pair_attempts = {}  \n",
    "\n",
    "            # Run through each prediction attempt\n",
    "            for attempt in range(1, NUM_ATTEMPTS + 1):\n",
    "                attempt_key = f\"attempt_{attempt}\"\n",
    "                pair_attempts[attempt_key] = [] # Init your attempt\n",
    "\n",
    "                # Try to get a prediction, with retries in case of failure\n",
    "                for retry in range(RETRY_ATTEMPTS):\n",
    "                    try:\n",
    "                        print(f\"    Predicting attempt #{attempt}, retry #{retry + 1}\")\n",
    "                        prediction = get_task_prediction(challenge_tasks=challenges,\n",
    "                                                         task_id=task_id,\n",
    "                                                         test_input_index=t)\n",
    "                        \n",
    "                        # If you get a valid prediction (list of lists of ints) with no error, then log the attempt\n",
    "                        pair_attempts[attempt_key] = prediction\n",
    "                        break  # Break the retry loop if prediction is successful\n",
    "                    except Exception as e:\n",
    "                        print(f\"Retrying: {e}\")\n",
    "                        if retry == RETRY_ATTEMPTS - 1:\n",
    "                            pair_attempts[attempt_key] = []  # Assign None if all retries fail\n",
    "\n",
    "            # After you get your attempts, append them to the task attempts\n",
    "            task_attempts.append(pair_attempts)\n",
    "\n",
    "        # Append the task attempts to the submission with the task_id as the key\n",
    "        submission[task_id] = task_attempts\n",
    "\n",
    "        # If you want to stop after N tasks, uncomment the below\n",
    "        if NUM_TASKS is not None and i + 1 == NUM_TASKS:\n",
    "            break\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating submission files and comparing it with solutions file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission file\n",
    "def create_submission_file(submission, file_name='submission.json'):\n",
    "    \"\"\"\n",
    "    Save a submission file to the specified file name\n",
    "    \"\"\"\n",
    "    with open(file_name, \"w\") as file:\n",
    "        json.dump(submission, file)\n",
    "\n",
    "    print (f\"Submission saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to compare submission with solutions\n",
    "def score_submission(submission_file_name, solutions) -> Tuple[float, int]:\n",
    "    \"\"\"\n",
    "    submission_file_name: str, the file name of your submission file\n",
    "    solutions: dict, the ground truth solutions you'd like to test against\n",
    "    \n",
    "    Read a submission from file, score it, then return the score\n",
    "    \"\"\"\n",
    "    print (f\"Scoring {submission_file_name}\\n\")\n",
    "\n",
    "    # Open your submission file\n",
    "    with open(submission_file_name, \"r\") as file:\n",
    "        submission = json.load(file)\n",
    "\n",
    "    total_score = 0\n",
    "    total_tasks = 0\n",
    "\n",
    "    # Loop through each task in your submission to grade it\n",
    "    for task_id, task_submission in submission.items():\n",
    "        total_tasks += 1\n",
    "        task_score = 0\n",
    "        num_pairs = len(task_submission)\n",
    "\n",
    "        # Go through each task. Most will only have 1\n",
    "        for pair_index, pair_attempts in enumerate(task_submission):\n",
    "            print(f\"Scoring Task {task_id} pair #{pair_index+1}\")\n",
    "            pair_correct = False\n",
    "\n",
    "            # Look at both of your attempts\n",
    "            for attempt_key, attempt in pair_attempts.items():\n",
    "                \n",
    "                # check to see if one is correct\n",
    "                if attempt == solutions[task_id][pair_index]:\n",
    "                    print(f\"Task Id {task_id} pair {pair_index+1} {attempt_key} matches solution\")\n",
    "                    pair_correct = True\n",
    "                    break # If it is correct, log it and break the loop\n",
    "\n",
    "            if pair_correct:\n",
    "                task_score += 1\n",
    "\n",
    "        task_score /= num_pairs\n",
    "        total_score += task_score\n",
    "\n",
    "    return {\n",
    "        'total_score': total_score,\n",
    "        'total_tasks_scored': total_tasks\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The main function to bring everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(task_set='training', NUM_TASKS=None, submission_file_name='submission.json'):\n",
    "    # Load datasets\n",
    "    challenges, solutions = load_tasks_from_file(task_set=task_sets[task_set])\n",
    "\n",
    "    # # Run the model\n",
    "    submission = run_model(challenges, NUM_TASKS=NUM_TASKS)\n",
    "\n",
    "    # Create (and overwrite) a submission file\n",
    "    create_submission_file(submission, file_name=submission_file_name)\n",
    "\n",
    "    # Score the submission\n",
    "    score_result = score_submission(solutions = solutions, submission_file_name=submission_file_name)\n",
    "\n",
    "    print(f\"Final score: {score_result['total_score']} of {score_result['total_tasks_scored']} ({round(score_result['total_score']/score_result['total_tasks_scored'] * 100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Prompt: You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. Identify the pattern, then apply that pattern to the test input to give a final output. Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[8, 6],\n",
      "[6, 4],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],\n",
      "[6, 8, 6, 8, 6, 8],\n",
      "[4, 6, 4, 6, 4, 6],\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[7, 9],\n",
      "[4, 3],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],\n",
      "[9, 7, 9, 7, 9, 7],\n",
      "[3, 4, 3, 4, 3, 4],\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[3, 2]\n",
      "[7, 8]]\n",
      "\n",
      "Your Response:\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. Identify the pattern, then apply that pattern to the test input to give a final output. Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. Training Examples\\nExample 1: Input\\n[\\n[8, 6],\\n[6, 4],]\\n\\nExample 1: Output\\n[\\n[8, 6, 8, 6, 8, 6],\\n[6, 4, 6, 4, 6, 4],\\n[6, 8, 6, 8, 6, 8],\\n[4, 6, 4, 6, 4, 6],\\n[8, 6, 8, 6, 8, 6],\\n[6, 4, 6, 4, 6, 4],]\\n\\nExample 2: Input\\n[\\n[7, 9],\\n[4, 3],]\\n\\nExample 2: Output\\n[\\n[7, 9, 7, 9, 7, 9],\\n[4, 3, 4, 3, 4, 3],\\n[9, 7, 9, 7, 9, 7],\\n[3, 4, 3, 4, 3, 4],\\n[7, 9, 7, 9, 7, 9],\\n[4, 3, 4, 3, 4, 3],]\\n\\nTest\\n[\\n[3, 2]\\n[7, 8]]\\n\\nYour Response:\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'max_tokens': 3000, 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting task #1 (00576224), pair #1\n",
      "    Predicting attempt #1, retry #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000211B65DFF50>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x00000211BAA6D350> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000211B65DEB70>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 14 Oct 2024 10:42:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mwzb2qixhfmrwz18lrxtmsu1'), (b'openai-processing-ms', b'2810'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'1996813'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'95ms'), (b'x-request-id', b'req_40981e99f2cea5be4ecea766d72bd937'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mLO.MUEt5XOR0KmnV3l4jD0W0VTggCEgSk8JFjtpzNQ-1728902563-1.0.1.1-agKPxSKC7vJHPFwb69Uw5U9mUZcJoAMnnEoaB3Siw_KT7imT1a5nZgW7eV8o9bk6Wv0k8EU.ZtIMoqKu5hZkUg; path=/; expires=Mon, 14-Oct-24 11:12:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=G41blcrA6ohC9ZvxqMBxQVxG1ES744VZC0zcV2RTURU-1728902563806-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d26f6cd3b39be3f-CPH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 14 Oct 2024 10:42:43 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-mwzb2qixhfmrwz18lrxtmsu1'), ('openai-processing-ms', '2810'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '2000000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '1996813'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '95ms'), ('x-request-id', 'req_40981e99f2cea5be4ecea766d72bd937'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=mLO.MUEt5XOR0KmnV3l4jD0W0VTggCEgSk8JFjtpzNQ-1728902563-1.0.1.1-agKPxSKC7vJHPFwb69Uw5U9mUZcJoAMnnEoaB3Siw_KT7imT1a5nZgW7eV8o9bk6Wv0k8EU.ZtIMoqKu5hZkUg; path=/; expires=Mon, 14-Oct-24 11:12:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=G41blcrA6ohC9ZvxqMBxQVxG1ES744VZC0zcV2RTURU-1728902563806-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8d26f6cd3b39be3f-CPH'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_40981e99f2cea5be4ecea766d72bd937\n",
      "DEBUG:root:Prompt: You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. Identify the pattern, then apply that pattern to the test input to give a final output. Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[8, 6],\n",
      "[6, 4],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],\n",
      "[6, 8, 6, 8, 6, 8],\n",
      "[4, 6, 4, 6, 4, 6],\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[7, 9],\n",
      "[4, 3],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],\n",
      "[9, 7, 9, 7, 9, 7],\n",
      "[3, 4, 3, 4, 3, 4],\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[3, 2]\n",
      "[7, 8]]\n",
      "\n",
      "Your Response:\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. Identify the pattern, then apply that pattern to the test input to give a final output. Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. Training Examples\\nExample 1: Input\\n[\\n[8, 6],\\n[6, 4],]\\n\\nExample 1: Output\\n[\\n[8, 6, 8, 6, 8, 6],\\n[6, 4, 6, 4, 6, 4],\\n[6, 8, 6, 8, 6, 8],\\n[4, 6, 4, 6, 4, 6],\\n[8, 6, 8, 6, 8, 6],\\n[6, 4, 6, 4, 6, 4],]\\n\\nExample 2: Input\\n[\\n[7, 9],\\n[4, 3],]\\n\\nExample 2: Output\\n[\\n[7, 9, 7, 9, 7, 9],\\n[4, 3, 4, 3, 4, 3],\\n[9, 7, 9, 7, 9, 7],\\n[3, 4, 3, 4, 3, 4],\\n[7, 9, 7, 9, 7, 9],\\n[4, 3, 4, 3, 4, 3],]\\n\\nTest\\n[\\n[3, 2]\\n[7, 8]]\\n\\nYour Response:\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'max_tokens': 3000, 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying: Invalid JSON output: content='[\\n[3, 2, 3, 2, 3, 2],\\n[7, 8, 7, 8, 7, 8],\\n[2, 3, 2, 3, 2, 3],\\n[8, 7, 8, 7, 8, 7],\\n[3, 2, 3, 2, 3, 2],\\n[7, 8, 7, 8, 7, 8]\\n]' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 368, 'total_tokens': 478, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'stop', 'logprobs': None} id='run-d9a441cc-f9e4-4cd4-932f-7eea8c55f21f-0' usage_metadata={'input_tokens': 368, 'output_tokens': 110, 'total_tokens': 478, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "    Predicting attempt #1, retry #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 14 Oct 2024 10:42:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mwzb2qixhfmrwz18lrxtmsu1'), (b'openai-processing-ms', b'2835'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'1996813'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'95ms'), (b'x-request-id', b'req_7bcb58b915555a141e7883db5615483e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d26f6dffa83be3f-CPH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 14 Oct 2024 10:42:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-mwzb2qixhfmrwz18lrxtmsu1', 'openai-processing-ms': '2835', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '1996813', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '95ms', 'x-request-id': 'req_7bcb58b915555a141e7883db5615483e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d26f6dffa83be3f-CPH', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_7bcb58b915555a141e7883db5615483e\n",
      "DEBUG:root:Prompt: You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. Identify the pattern, then apply that pattern to the test input to give a final output. Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[8, 6],\n",
      "[6, 4],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],\n",
      "[6, 8, 6, 8, 6, 8],\n",
      "[4, 6, 4, 6, 4, 6],\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[7, 9],\n",
      "[4, 3],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],\n",
      "[9, 7, 9, 7, 9, 7],\n",
      "[3, 4, 3, 4, 3, 4],\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[3, 2]\n",
      "[7, 8]]\n",
      "\n",
      "Your Response:\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. Identify the pattern, then apply that pattern to the test input to give a final output. Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. Training Examples\\nExample 1: Input\\n[\\n[8, 6],\\n[6, 4],]\\n\\nExample 1: Output\\n[\\n[8, 6, 8, 6, 8, 6],\\n[6, 4, 6, 4, 6, 4],\\n[6, 8, 6, 8, 6, 8],\\n[4, 6, 4, 6, 4, 6],\\n[8, 6, 8, 6, 8, 6],\\n[6, 4, 6, 4, 6, 4],]\\n\\nExample 2: Input\\n[\\n[7, 9],\\n[4, 3],]\\n\\nExample 2: Output\\n[\\n[7, 9, 7, 9, 7, 9],\\n[4, 3, 4, 3, 4, 3],\\n[9, 7, 9, 7, 9, 7],\\n[3, 4, 3, 4, 3, 4],\\n[7, 9, 7, 9, 7, 9],\\n[4, 3, 4, 3, 4, 3],]\\n\\nTest\\n[\\n[3, 2]\\n[7, 8]]\\n\\nYour Response:\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'max_tokens': 3000, 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying: Invalid JSON output: content='[\\n[3, 2, 3, 2, 3, 2],\\n[7, 8, 7, 8, 7, 8],\\n[2, 3, 2, 3, 2, 3],\\n[8, 7, 8, 7, 8, 7],\\n[3, 2, 3, 2, 3, 2],\\n[7, 8, 7, 8, 7, 8]\\n]' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 368, 'total_tokens': 478, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'stop', 'logprobs': None} id='run-90c868eb-5c17-443c-a532-ef181f81d0a6-0' usage_metadata={'input_tokens': 368, 'output_tokens': 110, 'total_tokens': 478, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "    Predicting attempt #1, retry #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 14 Oct 2024 10:42:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mwzb2qixhfmrwz18lrxtmsu1'), (b'openai-processing-ms', b'2666'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'1996813'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'95ms'), (b'x-request-id', b'req_75a8b68639545605da9c2fdb4b352a3a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d26f6f2ed57be3f-CPH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 14 Oct 2024 10:42:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-mwzb2qixhfmrwz18lrxtmsu1', 'openai-processing-ms': '2666', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '1996813', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '95ms', 'x-request-id': 'req_75a8b68639545605da9c2fdb4b352a3a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d26f6f2ed57be3f-CPH', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_75a8b68639545605da9c2fdb4b352a3a\n",
      "DEBUG:root:Prompt: You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. Identify the pattern, then apply that pattern to the test input to give a final output. Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[8, 6],\n",
      "[6, 4],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],\n",
      "[6, 8, 6, 8, 6, 8],\n",
      "[4, 6, 4, 6, 4, 6],\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[7, 9],\n",
      "[4, 3],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],\n",
      "[9, 7, 9, 7, 9, 7],\n",
      "[3, 4, 3, 4, 3, 4],\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[3, 2]\n",
      "[7, 8]]\n",
      "\n",
      "Your Response:\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. Identify the pattern, then apply that pattern to the test input to give a final output. Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. Training Examples\\nExample 1: Input\\n[\\n[8, 6],\\n[6, 4],]\\n\\nExample 1: Output\\n[\\n[8, 6, 8, 6, 8, 6],\\n[6, 4, 6, 4, 6, 4],\\n[6, 8, 6, 8, 6, 8],\\n[4, 6, 4, 6, 4, 6],\\n[8, 6, 8, 6, 8, 6],\\n[6, 4, 6, 4, 6, 4],]\\n\\nExample 2: Input\\n[\\n[7, 9],\\n[4, 3],]\\n\\nExample 2: Output\\n[\\n[7, 9, 7, 9, 7, 9],\\n[4, 3, 4, 3, 4, 3],\\n[9, 7, 9, 7, 9, 7],\\n[3, 4, 3, 4, 3, 4],\\n[7, 9, 7, 9, 7, 9],\\n[4, 3, 4, 3, 4, 3],]\\n\\nTest\\n[\\n[3, 2]\\n[7, 8]]\\n\\nYour Response:\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'max_tokens': 3000, 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying: Invalid JSON output: content='[\\n[3, 2, 3, 2, 3, 2],\\n[7, 8, 7, 8, 7, 8],\\n[2, 3, 2, 3, 2, 3],\\n[8, 7, 8, 7, 8, 7],\\n[3, 2, 3, 2, 3, 2],\\n[7, 8, 7, 8, 7, 8]\\n]' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 368, 'total_tokens': 478, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'stop', 'logprobs': None} id='run-609103d1-d92d-47a9-9a2c-017f89206e81-0' usage_metadata={'input_tokens': 368, 'output_tokens': 110, 'total_tokens': 478, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "    Predicting attempt #2, retry #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 14 Oct 2024 10:42:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mwzb2qixhfmrwz18lrxtmsu1'), (b'openai-processing-ms', b'2337'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'1996813'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'95ms'), (b'x-request-id', b'req_ae4e5cd50afea63de5a71c7a025f7299'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d26f704cb1dbe3f-CPH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 14 Oct 2024 10:42:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-mwzb2qixhfmrwz18lrxtmsu1', 'openai-processing-ms': '2337', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '1996813', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '95ms', 'x-request-id': 'req_ae4e5cd50afea63de5a71c7a025f7299', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d26f704cb1dbe3f-CPH', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_ae4e5cd50afea63de5a71c7a025f7299\n",
      "DEBUG:root:Prompt: You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. Identify the pattern, then apply that pattern to the test input to give a final output. Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[8, 6],\n",
      "[6, 4],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],\n",
      "[6, 8, 6, 8, 6, 8],\n",
      "[4, 6, 4, 6, 4, 6],\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[7, 9],\n",
      "[4, 3],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],\n",
      "[9, 7, 9, 7, 9, 7],\n",
      "[3, 4, 3, 4, 3, 4],\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[3, 2]\n",
      "[7, 8]]\n",
      "\n",
      "Your Response:\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. Identify the pattern, then apply that pattern to the test input to give a final output. Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. Training Examples\\nExample 1: Input\\n[\\n[8, 6],\\n[6, 4],]\\n\\nExample 1: Output\\n[\\n[8, 6, 8, 6, 8, 6],\\n[6, 4, 6, 4, 6, 4],\\n[6, 8, 6, 8, 6, 8],\\n[4, 6, 4, 6, 4, 6],\\n[8, 6, 8, 6, 8, 6],\\n[6, 4, 6, 4, 6, 4],]\\n\\nExample 2: Input\\n[\\n[7, 9],\\n[4, 3],]\\n\\nExample 2: Output\\n[\\n[7, 9, 7, 9, 7, 9],\\n[4, 3, 4, 3, 4, 3],\\n[9, 7, 9, 7, 9, 7],\\n[3, 4, 3, 4, 3, 4],\\n[7, 9, 7, 9, 7, 9],\\n[4, 3, 4, 3, 4, 3],]\\n\\nTest\\n[\\n[3, 2]\\n[7, 8]]\\n\\nYour Response:\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'max_tokens': 3000, 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying: Invalid JSON output: content='[\\n[3, 2, 3, 2, 3, 2],\\n[7, 8, 7, 8, 7, 8],\\n[2, 3, 2, 3, 2, 3],\\n[8, 7, 8, 7, 8, 7],\\n[3, 2, 3, 2, 3, 2],\\n[7, 8, 7, 8, 7, 8]\\n]' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 368, 'total_tokens': 478, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'stop', 'logprobs': None} id='run-94c08889-ae69-46c7-a8de-323bc3cefd97-0' usage_metadata={'input_tokens': 368, 'output_tokens': 110, 'total_tokens': 478, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "    Predicting attempt #2, retry #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 14 Oct 2024 10:42:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mwzb2qixhfmrwz18lrxtmsu1'), (b'openai-processing-ms', b'2355'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'1996813'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'95ms'), (b'x-request-id', b'req_c801b26706e0dba87eac0a3bb58fef11'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d26f7147d37be3f-CPH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 14 Oct 2024 10:42:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-mwzb2qixhfmrwz18lrxtmsu1', 'openai-processing-ms': '2355', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '1996813', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '95ms', 'x-request-id': 'req_c801b26706e0dba87eac0a3bb58fef11', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d26f7147d37be3f-CPH', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_c801b26706e0dba87eac0a3bb58fef11\n",
      "DEBUG:root:Prompt: You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. Identify the pattern, then apply that pattern to the test input to give a final output. Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. Training Examples\n",
      "Example 1: Input\n",
      "[\n",
      "[8, 6],\n",
      "[6, 4],]\n",
      "\n",
      "Example 1: Output\n",
      "[\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],\n",
      "[6, 8, 6, 8, 6, 8],\n",
      "[4, 6, 4, 6, 4, 6],\n",
      "[8, 6, 8, 6, 8, 6],\n",
      "[6, 4, 6, 4, 6, 4],]\n",
      "\n",
      "Example 2: Input\n",
      "[\n",
      "[7, 9],\n",
      "[4, 3],]\n",
      "\n",
      "Example 2: Output\n",
      "[\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],\n",
      "[9, 7, 9, 7, 9, 7],\n",
      "[3, 4, 3, 4, 3, 4],\n",
      "[7, 9, 7, 9, 7, 9],\n",
      "[4, 3, 4, 3, 4, 3],]\n",
      "\n",
      "Test\n",
      "[\n",
      "[3, 2]\n",
      "[7, 8]]\n",
      "\n",
      "Your Response:\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'You are a bot that is very good at solving puzzles. Below is a list of input and output pairs with a pattern. Identify the pattern, then apply that pattern to the test input to give a final output. Your response should be a valid JSON list of lists, containing only integers. Do not include explanations, titles, or metadata. Training Examples\\nExample 1: Input\\n[\\n[8, 6],\\n[6, 4],]\\n\\nExample 1: Output\\n[\\n[8, 6, 8, 6, 8, 6],\\n[6, 4, 6, 4, 6, 4],\\n[6, 8, 6, 8, 6, 8],\\n[4, 6, 4, 6, 4, 6],\\n[8, 6, 8, 6, 8, 6],\\n[6, 4, 6, 4, 6, 4],]\\n\\nExample 2: Input\\n[\\n[7, 9],\\n[4, 3],]\\n\\nExample 2: Output\\n[\\n[7, 9, 7, 9, 7, 9],\\n[4, 3, 4, 3, 4, 3],\\n[9, 7, 9, 7, 9, 7],\\n[3, 4, 3, 4, 3, 4],\\n[7, 9, 7, 9, 7, 9],\\n[4, 3, 4, 3, 4, 3],]\\n\\nTest\\n[\\n[3, 2]\\n[7, 8]]\\n\\nYour Response:\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'max_tokens': 3000, 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying: Invalid JSON output: content='[\\n[3, 2, 3, 2, 3, 2],\\n[7, 8, 7, 8, 7, 8],\\n[2, 3, 2, 3, 2, 3],\\n[8, 7, 8, 7, 8, 7],\\n[3, 2, 3, 2, 3, 2],\\n[7, 8, 7, 8, 7, 8]\\n]' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 368, 'total_tokens': 478, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'stop', 'logprobs': None} id='run-8e4b18fb-2893-4501-9397-90e9574a94a2-0' usage_metadata={'input_tokens': 368, 'output_tokens': 110, 'total_tokens': 478, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "    Predicting attempt #2, retry #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 14 Oct 2024 10:42:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mwzb2qixhfmrwz18lrxtmsu1'), (b'openai-processing-ms', b'2597'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'1996813'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'95ms'), (b'x-request-id', b'req_fdd9a3b5300a16908a0e63cb0170f140'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8d26f7244944be3f-CPH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 14 Oct 2024 10:42:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-mwzb2qixhfmrwz18lrxtmsu1', 'openai-processing-ms': '2597', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '1996813', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '95ms', 'x-request-id': 'req_fdd9a3b5300a16908a0e63cb0170f140', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8d26f7244944be3f-CPH', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_fdd9a3b5300a16908a0e63cb0170f140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying: Invalid JSON output: content='[\\n[3, 2, 3, 2, 3, 2],\\n[7, 8, 7, 8, 7, 8],\\n[2, 3, 2, 3, 2, 3],\\n[8, 7, 8, 7, 8, 7],\\n[3, 2, 3, 2, 3, 2],\\n[7, 8, 7, 8, 7, 8]\\n]' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 368, 'total_tokens': 478, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'stop', 'logprobs': None} id='run-7679d6a9-bc66-4a5b-a531-cc93bf100928-0' usage_metadata={'input_tokens': 368, 'output_tokens': 110, 'total_tokens': 478, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "Submission saved to submission.json\n",
      "Scoring submission.json\n",
      "\n",
      "Scoring Task 00576224 pair #1\n",
      "Final score: 0.0 of 1 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "main(task_set='evaluation', NUM_TASKS=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
